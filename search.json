[
  {
    "objectID": "visual-exploration-of-the-data.html",
    "href": "visual-exploration-of-the-data.html",
    "title": "Visual Exploration",
    "section": "",
    "text": "Going beyond the basic statistics and comparison with the u2gigs.com statistics, I explored the data in a more visual manner.",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "6. Visual Exploration"
    ]
  },
  {
    "objectID": "visual-exploration-of-the-data.html#load-custom-concertdata-package",
    "href": "visual-exploration-of-the-data.html#load-custom-concertdata-package",
    "title": "Visual Exploration",
    "section": "Load custom concertData package",
    "text": "Load custom concertData package\nFirst we load my custom concertData package where I organized all the functions to analyze the U2 concert data. This R package is available on my GitHub page at: https://github.com/vanleeuwen-hans/concertData.\n\nlibrary(devtools)\ndevtools::install_github(\"vanleeuwen-hans/concertData\")\nlibrary(concertData)\n\nLoad the u2data file.\n\n# read the u2 concertData\nu2data &lt;- read_concertData_csv('u2data/u2data_all_shows_clean_final.csv')",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "6. Visual Exploration"
    ]
  },
  {
    "objectID": "visual-exploration-of-the-data.html#u2-shows-throughout-the-week",
    "href": "visual-exploration-of-the-data.html#u2-shows-throughout-the-week",
    "title": "Visual Exploration",
    "section": "U2 shows throughout the week",
    "text": "U2 shows throughout the week\nLet‚Äôs see what days of the week the members of U2 prefer to play their shows. Saturday and Friday are the ones.\n\n# get weekday counts\nweekday_count &lt;- count_shows_by_weekday(u2data)\n\n# Extract the weekdays into a vector\nweekdays &lt;- as.character(weekday_count$weekday)\n\n# plot data\nlibrary(ggplot2)\nggplot(data=weekday_count, aes(x=weekday, y=count)) +\n  geom_bar(stat=\"identity\", fill=\"steelblue\")+\n  geom_text(aes(label=count), vjust=1.6, color=\"white\", position = position_dodge(0.9), size=3.5)+\n  scale_x_discrete(limits = weekdays)+\n  ggtitle(\"U2 shows throughout the week\")+\n  theme(plot.title = element_text(hjust = 0.5))+\n  xlab(\"Day of the week\") + ylab(\"Number of shows\")\n\n\n\n\n\n\n\n# check that weekday counts of shows counts match the number of unique shows in the data\nprint(sum(weekday_count$count))\n\n[1] 2209\n\nprint(nrow(unique(u2data[,c('showID')])))\n\n[1] 2209",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "6. Visual Exploration"
    ]
  },
  {
    "objectID": "visual-exploration-of-the-data.html#u2-shows-throughout-the-year",
    "href": "visual-exploration-of-the-data.html#u2-shows-throughout-the-year",
    "title": "Visual Exploration",
    "section": "U2 shows throughout the year",
    "text": "U2 shows throughout the year\nLet‚Äôs see what months of the year the members of U2 prefer to play their shows. The Top 3 months are November, October and May. January seems to be either too cold, or after the holiday season some start-up time is needed. In August they tend the take a well-deserved vacation.\n\n# get monthly counts\nmonth_counts &lt;- count_shows_by_month(u2data)\n\n# Extract the months into a vector\nmonths &lt;- as.character(month_counts$month)\n\n# plot number of shows by month\nggplot(data=month_counts, aes(x=month, y=count)) +\n  geom_bar(stat=\"identity\", fill=\"steelblue\")+\n  geom_text(aes(label=count), vjust=1.6, color=\"white\", position = position_dodge(0.9), size=3.5)+\n  scale_x_discrete(limits = months)+\n  ggtitle(\"U2 shows throughout the year\")+\n  theme(plot.title = element_text(hjust = 0.5))+\n  xlab(\"Month\") + ylab(\"Number of shows\")\n\n\n\n\n\n\n\n# check that month counts of shows counts match the number of unique shows in the data\nprint(sum(month_counts$count))\n\n[1] 2209\n\nprint(nrow(unique(u2data[,c('showID')])))\n\n[1] 2209",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "6. Visual Exploration"
    ]
  },
  {
    "objectID": "visual-exploration-of-the-data.html#u2-shows-over-the-decades",
    "href": "visual-exploration-of-the-data.html#u2-shows-over-the-decades",
    "title": "Visual Exploration",
    "section": "U2 shows over the decades",
    "text": "U2 shows over the decades\nThe 80s was definitely the decade where U2 was most active with regards to touring!\n\n# get decade counts\ndecade_counts &lt;- count_shows_by_decade(u2data)\n\n# Extract the decades into a vector\ndecades &lt;- as.character(decade_counts$decade)\n\n# plot number of shows by decade\nggplot(data=decade_counts, aes(x=decade, y=count)) +\n  geom_bar(stat=\"identity\", fill=\"steelblue\")+\n  geom_text(aes(label=count), vjust=1.6, color=\"white\", position = position_dodge(0.9), size=3.5)+\n  scale_x_discrete(limits = decades)+\n  ggtitle(\"U2 shows over the decades\")+\n  theme(plot.title = element_text(hjust = 0.5))+\n  xlab(\"Decade\") + ylab(\"Number of shows\")\n\n\n\n\n\n\n\n# check that decade counts of shows counts match the number of unique shows in the data\nprint(sum(decade_counts$count))\n\n[1] 2209\n\nprint(nrow(unique(u2data[,c('showID')])))\n\n[1] 2209",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "6. Visual Exploration"
    ]
  },
  {
    "objectID": "visual-exploration-of-the-data.html#opening-and-closing-songs",
    "href": "visual-exploration-of-the-data.html#opening-and-closing-songs",
    "title": "Visual Exploration",
    "section": "Opening and Closing songs",
    "text": "Opening and Closing songs\nZoo Station and 40 win by far as opening and closing songs, respectively. Interesting anecdote, when I asked my wife what was the top opening song she was convinced it was Vertigo as she remembered that almost all Vertigo Tour shows opened with that song. When we inspected the different legs of that tour we saw that it was not Vertigo but City of Blinding Lights that mostly opened. Of course, the memory is biased towards the shows that we attended. That‚Äôs why it was good to have the data at hand to show the overall picture. Note: snippets were excluded from this analysis.\nThe first table below shows the top 3 opening songs for each tour, while the second table below shows the top opening song all time, for each year since 1976. Note that in some of these years there were no tours but a perhaps a few small shows or TV appearances. To come back to the Vertigo example, in that second table you can see that City of Blinding Lights opened 86 shows of the Vertigo Tour while Vertigo opened 36 shows.\n\n# load libraries\nlibrary(ggplot2)\n\n# Get top 10 opening songs \nopening_songs &lt;- find_most_played_opening_songs(u2data, n = 10)\n\n# Visualize opening songs\nggplot(opening_songs, aes(x = reorder(song_title, times_played), y = times_played)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n  coord_flip() +\n  theme_minimal() +\n  labs(title = \"Most Common U2 Opening Songs\",\n       x = \"Song\",\n       y = \"Number of Times Used as Opener\") +\n  theme(axis.text.y = element_text(size = 10))\n\n\n\n\n\n\n\n# Get top 10 closing songs\nclosing_songs &lt;- find_most_played_closing_songs(u2data, n = 10)\n\n# Visualize closing songs\nggplot(closing_songs, aes(x = reorder(song_title, times_played), y = times_played)) +\n  geom_bar(stat = \"identity\", fill = \"indianred\") +\n  coord_flip() +\n  theme_minimal() +\n  labs(title = \"Most Common U2 Closing Songs\",\n       x = \"Song\",\n       y = \"Number of Times Used as Closer\") +\n  theme(axis.text.y = element_text(size = 10))\n\n\n\n\n\n\n\n# Get top 3 opening songs per tour \ntop_3_openers_by_tour &lt;- find_most_played_opening_songs_by_tour(u2data, top_n = 3)\n# Print results\nhead(top_3_openers_by_tour, n = nrow(top_3_openers_by_tour))\n\n                                            tour\n1       U2 U2:UV Achtung Baby Live at the Sphere\n2                   U2 Stories of Surrender Tour\n3                   U2 Stories of Surrender Tour\n4                   U2 Stories of Surrender Tour\n5                       U2 Joshua Tree Tour 2019\n6                 U2 Experience + Innocence Tour\n7                 U2 Experience + Innocence Tour\n8              U2 Songs Of Experience Promo Tour\n9              U2 Songs Of Experience Promo Tour\n10             U2 Songs Of Experience Promo Tour\n11                      U2 Joshua Tree Tour 2017\n12                U2 Innocence + Experience Tour\n13              U2 Songs Of Innocence Promo Tour\n14              U2 Songs Of Innocence Promo Tour\n15              U2 Songs Of Innocence Promo Tour\n16                                  U2 360¬∞ Tour\n17                                  U2 360¬∞ Tour\n18                                  U2 360¬∞ Tour\n19          U2 No Line On The Horizon Promo Tour\n20          U2 No Line On The Horizon Promo Tour\n21          U2 No Line On The Horizon Promo Tour\n22                               U2 Vertigo Tour\n23                               U2 Vertigo Tour\n24                               U2 Vertigo Tour\n25 U2 How To Dismantle An Atomic Bomb Promo Tour\n26 U2 How To Dismantle An Atomic Bomb Promo Tour\n27 U2 How To Dismantle An Atomic Bomb Promo Tour\n28                             U2 Elevation Tour\n29                             U2 Elevation Tour\n30 U2 All That You Can't Leave Behind Promo Tour\n31 U2 All That You Can't Leave Behind Promo Tour\n32 U2 All That You Can't Leave Behind Promo Tour\n33                               U2 PopMart Tour\n34                                U2 ZOO TV Tour\n35                              U2 Lovetown Tour\n36                              U2 Lovetown Tour\n37                              U2 Lovetown Tour\n38                           U2 Joshua Tree Tour\n39                           U2 Joshua Tree Tour\n40                           U2 Joshua Tree Tour\n41                         U2 Conspiracy Of Hope\n42                         U2 Conspiracy Of Hope\n43                    U2 Unforgettable Fire Tour\n44                    U2 Unforgettable Fire Tour\n45                    U2 Unforgettable Fire Tour\n46                                   U2 War Tour\n47                                   U2 War Tour\n48                                   U2 War Tour\n49                               U2 October Tour\n50                               U2 October Tour\n51                               U2 October Tour\n52                                   U2 Boy Tour\n53                                   U2 Boy Tour\n54                                   U2 Boy Tour\n55                  U2 11 O'Clock Tick Tock Tour\n56                  U2 11 O'Clock Tick Tock Tour\n57                                 U2 Early Days\n58                                 U2 Early Days\n59                                 U2 Early Days\n60                              U2 Various Dates\n61                              U2 Various Dates\n62                              U2 Various Dates\n                               song_title times_played\n1                             Zoo Station           40\n2                 City of Blinding Lights           27\n3                    Stories of Surrender           11\n4                                 Vertigo            2\n5                    Sunday Bloody Sunday           15\n6                            The Blackout           33\n7                Love Is All We Have Left           27\n8                           American Soul            1\n9                           Beautiful Day            1\n10                Get Out Of Your Own Way            1\n11                   Sunday Bloody Sunday           51\n12           The Miracle (of Joey Ramone)           76\n13           The Miracle (of Joey Ramone)            8\n14                    Every Breaking Wave            3\n15                          Beautiful Day            1\n16                                Breathe           43\n17          Return of the Stingray Guitar           33\n18                          Beautiful Day            3\n19                      Get on Your Boots           10\n20                                Breathe            2\n21                            Magnificent            2\n22                City of Blinding Lights           86\n23                                Vertigo           36\n24                 Love and Peace or Else            9\n25                                Vertigo            6\n26                     All Because Of You            1\n27                Original Of The Species            1\n28                              Elevation          112\n29                          Beautiful Day            1\n30                          Beautiful Day            8\n31                              Elevation            6\n32 Stuck in a Moment You Can't Get Out Of            1\n33                                   Mofo           93\n34                            Zoo Station          156\n35         Where the Streets Have No Name           24\n36                    Bullet the Blue Sky           10\n37                           Hawkmoon 269            8\n38         Where the Streets Have No Name           87\n39                            Stand By Me           18\n40                    Bullet the Blue Sky            4\n41                                    MLK            5\n42                        C'mon Everybody            1\n43                   11 O'Clock Tick Tock           87\n44                                 Gloria           13\n45                         Out of Control            4\n46                         Out of Control           53\n47                                 Gloria           40\n48                              Surrender            2\n49                                 Gloria           75\n50               With a Shout (Jerusalem)            3\n51                   11 O'Clock Tick Tock            2\n52                              The Ocean           57\n53                          I Will Follow           15\n54                   11 O'Clock Tick Tock           13\n55                   11 O'Clock Tick Tock           10\n56                          I Will Follow            1\n57                         Out of Control           13\n58                    Concentration Cramp            7\n59                       2-4-6-8 Motorway            6\n60                                    One           14\n61                                Vertigo            9\n62                                 Desire            7\n\n# get top opening song by year\nopening_timeline &lt;- find_most_played_opening_song_by_year(u2data)\nhead(opening_timeline, n = nrow(opening_timeline))\n\n   year                                 song_title times_played\n1  1976                            Show Me The Way            1\n2  1977                           2-4-6-8 Motorway            1\n3  1977                               Batman Theme            1\n4  1977                       Don't Believe A Word            1\n5  1977                         Jumpin' Jack Flash            1\n6  1977                            Show Me The Way            1\n7  1978                           2-4-6-8 Motorway            5\n8  1979                             Out of Control           10\n9  1980                       11 O'Clock Tick Tock           27\n10 1981                                     Gloria           46\n11 1981                                  The Ocean           46\n12 1982                                     Gloria           30\n13 1983                                     Gloria           41\n14 1984                       11 O'Clock Tick Tock           30\n15 1985                       11 O'Clock Tick Tock           57\n16 1986                                        MLK            5\n17 1987             Where the Streets Have No Name           88\n18 1988                    When Love Comes To Town            2\n19 1989             Where the Streets Have No Name           22\n20 1990             Where the Streets Have No Name            2\n21 1992                                Zoo Station          103\n22 1993                                Zoo Station           54\n23 1994                                   One Love            1\n24 1995                                I Feel Good            1\n25 1995                              Miss Sarajevo            1\n26 1995                                  The Cross            1\n27 1995        Two Shots of Happy, One Shot of Sad            1\n28 1996                              Tower Of Song            1\n29 1997                                       Mofo           79\n30 1998                                       Mofo           15\n31 1999                                    New Day            3\n32 2000                              Beautiful Day            8\n33 2001                                  Elevation          112\n34 2002                            American Prayer            1\n35 2002                           Beat On The Brat            1\n36 2002                              Beautiful Day            1\n37 2002                          Because The Night            1\n38 2002    It's Only Rock 'n' Roll (But I Like It)            1\n39 2002                                        One            1\n40 2002               The Hands That Built America            1\n41 2002                                    Walk On            1\n42 2002                     When The Stars Go Blue            1\n43 2003                       Falling At Your Feet            3\n44 2003               The Hands That Built America            3\n45 2004                                    Vertigo            6\n46 2005                    City of Blinding Lights           69\n47 2006                    City of Blinding Lights           20\n48 2007                     Don't Give Up (Africa)            1\n49 2007                            Redemption Song            1\n50 2007                  Stay (Faraway, So Close!)            1\n51 2007                                    Vertigo            1\n52 2007                  Wave of Sorrow (Birdland)            1\n53 2008                       All You Need Is Love            2\n54 2009                                    Breathe           47\n55 2010              Return of the Stingray Guitar           32\n56 2011                              Beautiful Day            3\n57 2012                            Angel of Harlem            1\n58 2012                              Carrickfergus            1\n59 2012         Christmas (Baby, Please Come Home)            1\n60 2012                                       Help            1\n61 2012                 I've Got You Under My Skin            1\n62 2012               Improvisation With Tinariwen            1\n63 2012                                     Mensch            1\n64 2012                              Night And Day            1\n65 2012                          The Auld Triangle            1\n66 2012                                    Walk On            1\n67 2012                              Where Or When            1\n68 2013                                Stand By Me            2\n69 2013                       Sunday Bloody Sunday            2\n70 2014               The Miracle (of Joey Ramone)            8\n71 2015               The Miracle (of Joey Ramone)           77\n72 2016                          Because The Night            1\n73 2016                                     Desire            1\n74 2016 I Still Haven't Found What I'm Looking For            1\n75 2016                         If It Be Your Will            1\n76 2016                Pride (In the Name of Love)            1\n77 2016            The People In Your Neighborhood            1\n78 2016                                    Vertigo            1\n79 2017                       Sunday Bloody Sunday           52\n80 2018                               The Blackout           33\n81 2019                       Sunday Bloody Sunday           15\n82 2020                   Happy Xmas (War Is Over)            1\n83 2020                         Larry O'gaff's Set            1\n84 2020                         Stairway To Heaven            1\n85 2021                                 In My Life            1\n86 2021                     Running To Stand Still            1\n87 2021                          We Are The People            1\n88 2022                    City of Blinding Lights           14\n89 2023                                Zoo Station           25\n90 2024                                Zoo Station           15",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "6. Visual Exploration"
    ]
  },
  {
    "objectID": "visual-exploration-of-the-data.html#set-list-variability-across-tours",
    "href": "visual-exploration-of-the-data.html#set-list-variability-across-tours",
    "title": "Visual Exploration",
    "section": "Set-list variability across tours",
    "text": "Set-list variability across tours\nHere are two examples of a U2 set list, from the Innocence + Experience Tour (2015) and the Joshua Tree Tour (2017), both in Amsterdam. These set-lists are actually used by the band during the show and the crew members give them to the fans after the show, sometimes.\n\n\nData preparation for set-list variability analysis\nNow we get to one of the main objectives of this project: how variable, or fixed, are the U2 set-lists? Let‚Äôs start with data preparation and calculations before we create several plots.\n\n# read the u2 concertData\nu2data &lt;- read_concertData_csv('u2data/u2data_all_shows_clean_final.csv')\n\n# List of tours to exclude as this analysis focuses on the regular tours done after a U2 album release.\nexcluded_tours &lt;- c(\n   \"U2 Stories of Surrender Tour\",\n   \"U2 Songs Of Experience Promo Tour\",\n   \"U2 Songs Of Innocence Promo Tour\",\n   \"U2 No Line On The Horizon Promo Tour\",\n   \"U2 How To Dismantle An Atomic Bomb Promo Tour\",\n   \"U2 All That You Can't Leave Behind Promo Tour\",\n   \"U2 Conspiracy Of Hope\",\n   \"U2 11 O'Clock Tick Tock Tour\",\n   \"U2 Early Days\",\n   \"U2 Various Dates\"\n)\n\n\n\nAverage number of songs per show\nIn the early days the U2 concerts were much shorter, for example after the launch of their first album ‚ÄòBoy‚Äô the average numbers of songs played at their concerts was about 10. In more recent tours the number is somewhere between 22 and 25. As mentioned on the Basic Statistics U2 Concerts page, I was lucky to have attended of the longest shows ever: 27 songs played.\n\n# get required package\nlibrary(ggplot2)\n\n# create data frame without excluded tours\ndata_selected_tours &lt;- concertData_remove_tours(u2data, excluded_tours)\n# remove shows without setlist\ndata_inc_snippets &lt;- concertData_remove_showsNoSetlist(data_selected_tours)\n\n# Get tours ordered chronologically\ntour_order &lt;- tour_order_by_date(data_inc_snippets, ascending = FALSE)\n  \n# Calculate tour-level statistics\ntour_stats &lt;- calculate_comprehensive_tour_statistics(data_inc_snippets, tour_order)\n\n# Average Songs per Show\nggplot(tour_stats, aes(x = tour, y = avg_songs_per_show)) +\n  geom_col(fill = \"blue\") +\n  geom_text(aes(label = round(avg_songs_per_show, 1)), \n            vjust = 2, size = 3) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Average Number of Songs per Show\",\n       x = \"Tour\",\n       y = \"Average Number of Songs\")\n\n\n\n\n\n\n\n\n\n\nNumber of shows per tour\nThe longest tour with most shows ever was the ZOO TV Tour in 1992-1993. That tour consisted of 5 legs and a total of 156 shows. That was the first tour when I saw U2 live, below a picture I took at the front rail in Nijmegen on August 3, 1993.\n\n\n\nU2 ZOO TV - Zooropa Tour, 3 Aug 1993, Nijmegen, The Netherlands\n\n\nIf you want to see a visual of the number of shows per tour aspect, layered on the world map, you can check out the U2 Tour Map Shiny app that I developed as part of this project.\n\n# get required package\nlibrary(ggplot2)\n\n# create data frame without excluded tours\ndata_selected_tours &lt;- concertData_remove_tours(u2data, excluded_tours)\n# remove shows without setlist\ndata_inc_snippets &lt;- concertData_remove_showsNoSetlist(data_selected_tours)\n\n# Get tours ordered chronologically\ntour_order &lt;- tour_order_by_date(data_inc_snippets, ascending = FALSE)\n\n# Calculate tour-level statistics\ntour_stats &lt;- calculate_comprehensive_tour_statistics(data_inc_snippets, tour_order)\n\n# Number of Shows per Tour\nggplot(tour_stats, aes(x = tour, y = total_shows)) +\n  geom_col(fill = \"red\") +\n  geom_text(aes(label = total_shows), \n            vjust = 2, size = 3) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Number of Shows per Tour\",\n       x = \"Tour\",\n       y = \"Number of Shows\")\n\n\n\n\n\n\n\n\n\n\nNumber of unique songs per tour\nThe more unique songs U2 plays during a tour the better for the fans who go to many shows. Like this we hope to hear the songs they do not play that often. For example, when we were in Honolulu, Hawaii, for the last show of the Vertigo Tour, they played ‚ÄòRockin‚Äô in the Free World‚Äô, together with Pearl Jam. That was a big party, or as Bono said: ‚ÄòA tribal gathering of the faithful, celebrity love island, beach party‚Äô üòÅ üèñÔ∏è See my summary/compilation video on YouTube.\n\n\n\nU2 Vertigo Tour, December 9, 2006, Honolulu\n\n\nIf we look at the graph we see that the 360¬∞ Tour had most unique songs played. There seems to be a correlation with the number of shows in the tour, but more about that further down.\n\n# get required package\nlibrary(ggplot2)\n\n# create data frame without excluded tours\ndata_selected_tours &lt;- concertData_remove_tours(u2data, excluded_tours)\n# remove shows without setlist\ndata_inc_snippets &lt;- concertData_remove_showsNoSetlist(data_selected_tours)\n\n# Get tours ordered chronologically\ntour_order &lt;- tour_order_by_date(data_inc_snippets, ascending = FALSE)\n\n# Calculate tour-level statistics\ntour_stats &lt;- calculate_comprehensive_tour_statistics(data_inc_snippets, tour_order)\n\n# Unique Songs per Tour\nggplot(tour_stats, aes(x = tour, y = total_unique_songs)) +\n  geom_col(fill = \"purple\") +\n  geom_text(aes(label = total_unique_songs), \n            vjust = 2, size = 3) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Number Unique Songs per Tour\",\n       x = \"Tour\",\n       y = \"Number of Unique Songs\")\n\n\n\n\n\n\n\n\n\n\nNumber of unique snippets per tour\nSnippets are short pieces of songs that are mixed into a regular song performance. These snippets can be from U2 songs or from any other artist. A well-know and loved snippet among U2 fans is ‚ÄòShine like stars‚Äô which is sometimes played at the end of ‚ÄôWith or without You‚Äù, for example here in this Joshua Tree concert in 1987. In the graph we see that the 360¬∞ Tour did not only have the most number of unique songs, but also the most number of unique snippets.\n\n# get required package\nlibrary(ggplot2)\n\n# create data frame without excluded tours\ndata_selected_tours &lt;- concertData_remove_tours(u2data, excluded_tours)\n# remove shows without setlist\ndata_inc_snippets &lt;- concertData_remove_showsNoSetlist(data_selected_tours)\n\n# Get tours ordered chronologically\ntour_order &lt;- tour_order_by_date(data_inc_snippets, ascending = FALSE)\n\n# Calculate tour-level statistics\ntour_stats &lt;- calculate_comprehensive_tour_statistics(data_inc_snippets, tour_order)\n\n# Unique Snippets per Tour\nggplot(tour_stats, aes(x = tour, y = total_unique_snippets)) +\n  geom_col(fill = \"orange\") +\n  geom_text(aes(label = total_unique_snippets), \n            vjust = 2, size = 3) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Number of Unique Snippets per Tour\",\n       x = \"Tour\",\n       y = \"Number of Unique Snippets\")\n\n\n\n\n\n\n\n\n\n\nCorrelation between number of shows and number of songs/snippets\nIn the correlation plot below we see a moderate positive correlation between the number shows played during a tour and the number of unique songs and snippets played during a tour. About 21% (0.462¬≤ = 0.213) of the variation in unique songs can be explained by the number of shows, and about 16% (0.398¬≤ = 0.158) of the variation in unique snippets can be explained by the number of shows. Thus, there is a pattern, but it‚Äôs not very strong - having more shows somewhat predicts having more unique songs and more unique snippets performed.\n\n# get required packages\nlibrary(ggplot2)\n\n# create data frame without excluded tours\ndata_selected_tours &lt;- concertData_remove_tours(u2data, excluded_tours)\n# remove shows without setlist\ndata_inc_snippets &lt;- concertData_remove_showsNoSetlist(data_selected_tours)\n\n# Get tours ordered chronologically\ntour_order &lt;- tour_order_by_date(data_inc_snippets, ascending = FALSE)\n\n# Calculate tour-level statistics\ntour_stats &lt;- calculate_comprehensive_tour_statistics(data_inc_snippets, tour_order)\n\n# Analyze correlation between number of shows and unique songs / snippets\ntour_correlation_data &lt;- calculate_tour_correlation_data(tour_stats)\n\n# Calculate correlations\ncorrelations &lt;- summarise(\n  tour_stats,\n  songs_correlation = cor(total_shows, total_unique_songs),\n  snippets_correlation = cor(total_shows, total_unique_snippets)\n)\n\n# Create plot\nggplot(tour_correlation_data, \n       aes(x = total_shows, y = unique_count)) +\n  geom_point(aes(color = tour), size = 3) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"blue\") +\n  facet_wrap(~ metric_type, scales = \"free_y\") +\n  theme_minimal() +\n  labs(\n    title = \"Correlation: Number of Shows vs Unique Songs/Snippets\",\n    x = \"Number of Shows\",\n    y = \"Number of Unique Songs/Snippets\"\n  ) +\n  theme(legend.position = \"right\") +\n  geom_text(data = data.frame(\n    metric_type = \"Unique Songs\",\n    x = Inf,\n    y = Inf,\n    label = sprintf(\"Correlation: %.3f\", correlations$songs_correlation)\n  ), aes(x = x, y = y, label = label),\n  hjust = 1, vjust = 1, size = 3, inherit.aes = FALSE) +\n  geom_text(data = data.frame(\n    metric_type = \"Unique Snippets\",\n    x = Inf,\n    y = Inf,\n    label = sprintf(\"Correlation: %.3f\", correlations$snippets_correlation)\n  ), aes(x = x, y = y, label = label),\n  hjust = 1, vjust = 1, size = 3, inherit.aes = FALSE)\n\n\n\n\n\n\n\n\n\n\nDistribution of song frequencies by tour\nThe plot below gives a visual indication of how often songs are played within a tour.\n\n# create data frame without excluded tours\ndata_selected_tours &lt;- concertData_remove_tours(u2data, excluded_tours)\n# remove shows without setlist\ndata_inc_snippets &lt;- concertData_remove_showsNoSetlist(data_selected_tours)\n# remove snippets\ndata_no_snippets &lt;- concertData_remove_snippets(data_inc_snippets)\n\n# Get tours ordered chronologically\ntour_order &lt;- tour_order_by_date(data_no_snippets, ascending = FALSE)\n\n# Calculate tour-level statistics\ntour_stats &lt;- calculate_comprehensive_tour_statistics(data_inc_snippets, tour_order)\n\n# Calculate song frequency across tours\nsong_frequency &lt;- calculate_song_frequency_across_tours(data_no_snippets, tour_stats, tour_order)\n\n\n# Song Frequency Distribution\nggplot(song_frequency, aes(x = song_frequency, y = tour)) +\n  geom_boxplot(outlier.shape = NA, fill = \"lightgrey\") +\n  geom_jitter(aes(color = tour), height = 0.2, alpha = 0.4) +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    axis.text.y = element_text(size = 8)\n  ) +\n  labs(title = \"Distribution of Song Frequencies by Tour\",\n       subtitle = \"How often are different songs played within each tour?\",\n       caption = \"Box shows 25th-75th percentiles, bold line is median\\nPoints show individual songs, shifted left/right by frequency\\nWider spread indicates more variation in how often songs are played\",\n       x = \"Song Frequency (Proportion of shows that a song is played)\",\n       y = \"Tour\")\n\n\n\n\n\n\n\n\n\n\nOverall set-list variability by tour\nIn this analysis one overall variability score was calculated for each tour based on the variability of the set-lists in all the shows of that tour. The values were normalized with the tour having the highest set-list variability getting a score of 1.0. As we can see that is the 360¬∞ Tour, which also had the highest number of unique songs and snippets played. The Joshua Tree Tour 2017-2019 scored the lowest. This can partly be explained by the fact that U2 started playing those shows by playing the full Joshua Tree album with the songs always in the order as on the original album.\n\n# create data frame without excluded tours\ndata_selected_tours &lt;- concertData_remove_tours(u2data, excluded_tours)\n# remove shows without setlist\ndata_inc_snippets &lt;- concertData_remove_showsNoSetlist(data_selected_tours)\n# remove snippets\ndata_no_snippets &lt;- concertData_remove_snippets(data_inc_snippets)\n\n# Get tours ordered chronologically\ntour_order &lt;- tour_order_by_date(data_no_snippets, ascending = FALSE)\n\n# Calculate tour-level statistics\ntour_stats &lt;- calculate_comprehensive_tour_statistics(data_inc_snippets, tour_order)\n\n# Create a normalized version of overall_variability (0-1 scale)\n# and add to tour_stats data in new data frame\nmax_overall_var &lt;- max(tour_stats$overall_variability)\ntour_stats_extended &lt;- mutate(tour_stats, \n                               normalized_variability = overall_variability / max_overall_var)\n\n# plot overall variability of tours, with normalized values\nggplot(tour_stats_extended, aes(x = tour)) +\n  # Bar for normalized variability\n  geom_col(aes(y = normalized_variability), fill = \"darkgreen\", alpha = 0.5) +\n  # Bar outline for actual variability\n  geom_col(aes(y = overall_variability / max_overall_var), fill = NA) +\n  # Add labels for both actual and normalized values\n  geom_text(aes(y = normalized_variability,\n                label = sprintf(\"%.2f\", normalized_variability)),\n            vjust = 2, size = 3) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Overall Setlist Variability by Tour\",\n       subtitle = \"Higher values mean more variability in the setlists of that tour\",\n       x = \"Tour\",\n       y = \"Variability Score\") +\n  coord_cartesian(ylim = c(0, 1.1))  # Set y-axis limit with some padding for labels\n\n\n\n\n\n\n\n\n\n\nSet-list variability heatmap\nBesides the overall variability score by tour, we can see in the analysis and plot below the variability across the set-list song positions within a tour. Here we can indeed see the block of conserved songs at the start of the Joshua Tree Tour 2017-2019 shows. But we see similar conserved blocks in other tours, for example the ZOO TV Tour, Innocence + Experience Tour, and the latest U2:UV Achtung Baby Live shows in the Sphere, Las Vegas.\nThis plot gives a very nice picture of the set-list variability within and across tours, a topic very often discussed by U2 fans as I mentioned on the Asking the Right Questions page of this report. Now with the data in hand and this visualization it is possible to have a more objective view.\n\n# create data frame without excluded tours\ndata_selected_tours &lt;- concertData_remove_tours(u2data, excluded_tours)\n# remove shows without setlist\ndata_inc_snippets &lt;- concertData_remove_showsNoSetlist(data_selected_tours)\n# remove snippets\ndata_no_snippets &lt;- concertData_remove_snippets(data_inc_snippets)\n\n# Get tours ordered chronologically\ntour_order &lt;- tour_order_by_date(data_no_snippets, ascending = FALSE)\n\n# Calculate tour-level statistics\ntour_stats &lt;- calculate_comprehensive_tour_statistics(data_inc_snippets, tour_order)\n\n# Create a normalized version of overall_variability (0-1 scale)\n# and add to tour_stats data in new data frame\nmax_overall_var &lt;- max(tour_stats$overall_variability)\ntour_stats_extended &lt;- mutate(tour_stats, \n                               normalized_variability = overall_variability / max_overall_var)\n\n# Calculate max songs for each tour\nmax_songs_by_tour &lt;- longest_setlist_by_tour(data_no_snippets)\n  \n# Analyze Song Positions in Setlists\nposition_analysis &lt;- analyze_song_positions(data_no_snippets, max_songs_by_tour, tour_order)\n\n# plot graph\nggplot() +\n  geom_tile(data = position_analysis,\n            aes(x = position_bin, y = tour, fill = variability)) +\n  geom_text(data = tour_stats_extended,\n            aes(x = max(position_analysis$position_bin),\n                y = tour, \n                label = sprintf(\"%.2f\", normalized_variability)),\n            size = 2,\n            color = \"black\",\n            hjust = -0.2) +\n  scale_fill_gradient(low = \"red\", high = \"blue\") +\n  scale_x_continuous(\n    breaks = seq(1, max(position_analysis$position_bin), by = 2),\n    labels = seq(1, max(position_analysis$position_bin), by = 2)\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    axis.text.y = element_text(size = 6)\n  ) +\n  labs(title = \"Setlist Variability by Tour\",\n       subtitle = \"How predictable is each song position across different shows?\",\n       caption = paste(\"Colors indicate variability: Red = highly predictable, Blue = highly variable\\n\",\n                      \"Text annotations show normalized tour variability (unique songs / avg songs per show)\"),\n       x = \"Song Position in Show\",\n       y = \"Tour\",\n       fill = \"Variability\\n(0-1 scale)\")",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "6. Visual Exploration"
    ]
  },
  {
    "objectID": "visual-exploration-of-the-data.html#world-maps-of-u2-concerts-locations",
    "href": "visual-exploration-of-the-data.html#world-maps-of-u2-concerts-locations",
    "title": "Visual Exploration",
    "section": "World maps of U2 concerts locations",
    "text": "World maps of U2 concerts locations\nThere are two areas in the world where U2 fans have noting too complain with reagrds to the number of concerts they get. However, there are other countries where they hardly ever come or not at all. Use the following visualizations to check this out.\n\nData pre-processing for world maps\nFirst the data was prepared for geographical visualizations. This means that we had to find the coordinates on planet Earth for the cities where U2 played their shows. In addition, a transformation of the data was done to display show counts by frequency.\n\n# read the u2 concertData\nu2data &lt;- read_concertData_csv('u2data/u2data_all_shows_clean_final.csv')\n\n# get unique shows from concert data fram\nunique_shows &lt;- extract_unique_shows(u2data)\n# Process unique locations\nunique_locations &lt;- get_concert_locations(unique_shows)\n\n# Initialize geocoded_cities\ngeocoded_cities &lt;- NULL\n# File path for geocoded cities\ngeocoded_file_path &lt;- \"u2data/geocoded_cities.csv\"\n# Check if file with geocodes exists and read it if it does\n# If file does not exist yet lookup the geocode for each location\n# and write to file for future use (avoiding time consuming geocode lookup)\ngeocoded_cities &lt;- geocode_cities(geocoded_file_path, unique_locations)\n\n# Create frequency counts for cities \ncity_frequency &lt;- create_city_frequency(unique_shows, geocoded_cities)\n\n# transform city counts and use bins\n# for example cities with 1 sow, 2-5 shows, 6-10 shows, 11-25 shows,\n# 26-50 shows, 51-100 shows, or cities with 100+ shows\nbreaks &lt;- c(0, 1, 5, 10, 25, 50, 100, Inf)\ncity_frequency_transformed &lt;- transform_city_frequency(city_frequency, breaks)\n\n# Create decade-based frequency \ncity_by_decade &lt;- create_decade_frequency(unique_shows, geocoded_cities)\n\n# Create validation report \nvalidation &lt;- tryCatch({\n  list(\n    total_shows = n_distinct(u2data$showID),\n    processed_shows = nrow(unique_shows),  \n    unique_cities = n_distinct(u2data$city),\n    unique_countries = n_distinct(u2data$country),\n    unique_tours = n_distinct(u2data$tour),\n    cities_with_coords = sum(!is.na(geocoded_cities$lat)),\n    total_song_performances = nrow(u2data),\n    shows_missing_setlist = sum(is.na(u2data$song_title)),\n    total_shows_in_frequency = sum(city_frequency$show_count)  \n  )\n}, error = function(e) {\n  stop(paste(\"Error creating validation report:\", e$message))\n})\n\n# Print validation report with additional checks\nprint(\"Data Validation Report:\")\n\n[1] \"Data Validation Report:\"\n\nprint(validation)\n\n$total_shows\n[1] 2209\n\n$processed_shows\n[1] 2209\n\n$unique_cities\n[1] 410\n\n$unique_countries\n[1] 49\n\n$unique_tours\n[1] 26\n\n$cities_with_coords\n[1] 413\n\n$total_song_performances\n[1] 39653\n\n$shows_missing_setlist\n[1] 298\n\n$total_shows_in_frequency\n[1] 2209\n\n# Additional validation checks\nif (validation$total_shows != validation$processed_shows) {\n  warning(sprintf(\"Mismatch in show counts: %d total vs %d processed\", \n                  validation$total_shows, validation$processed_shows))\n}\nif (validation$total_shows != validation$total_shows_in_frequency) {\n  warning(sprintf(\"Mismatch in frequency counts: %d total vs %d in frequency table\", \n                  validation$total_shows, validation$total_shows_in_frequency))\n}\n\n\n\nWorld map using log scale and intensity\nIn this world map we see the places where U2 played, and how often, since they started in the late seventies of the previous century.\n\n# Using a log scale for the size/color intensity\n\n# libraries\nlibrary(ggplot2)\nlibrary(maps)\n\n# create map\nworld_map &lt;- map_data(\"world\")\n\n# Create date range string for subtitle\ndate_range &lt;- paste(\n  format(min(city_frequency_transformed$first_show), \"%B %Y\"),\n  \"to\",\n  format(max(city_frequency_transformed$last_show), \"%B %Y\")\n)\n\n# create plot\nworld_map &lt;- ggplot() +\n  # Base world map\n  geom_polygon(data = world_map, \n               aes(x = long, y = lat, group = group),\n               fill = \"lightgray\", color = \"white\") +\n  # Add points for each city\n  geom_point(data = city_frequency_transformed,\n             aes(x = long, y = lat, \n                 size = show_category,\n                 color = show_category),\n             alpha = 0.7) +\n  # Customize the appearance\n  scale_size_discrete(range = c(2, 8)) +\n  scale_color_brewer(palette = \"YlOrRd\") +\n  guides(\n    color = guide_legend(\n      title = \"Number of Shows\",\n      override.aes = list(size = c(2, 3, 4, 5, 6, 7, 8))  # Make legend dots increase in size\n    ),\n    size = \"none\"  # Hide separate size legend\n  ) +\n  theme_minimal() +\n  labs(title = \"U2 Concert Locations Worldwide\",\n       subtitle = date_range,\n       x = \"Longitude\",\n       y = \"Latitude\") +\n  theme(legend.position = \"right\") +\n  # Adjust the map proportions\n  coord_fixed(1.3)\n\n# print plot\nprint(world_map)\n\n\n\n\n\n\n\n\n\n\nWorld map by decades\nHere we see the break down by decades: where and how often did they play in each decade since they started.\n\n# Create decade-based maps\n\n# Libraries\nlibrary(ggplot2)\nlibrary(maps)\nlibrary(RColorBrewer)\n\n# Create world map base\nworld_map &lt;- map_data(\"world\")\n\n# Create visualization\ndecades_plot &lt;- ggplot(data = city_by_decade) +\n  geom_polygon(data = world_map, \n               aes(x = long, y = lat, group = group),\n               fill = \"lightgray\", color = \"white\") +\n  geom_point(aes(x = long, y = lat, \n                 size = show_count,\n                 color = show_count),\n             alpha = 0.7) +\n  scale_size_continuous(name = \"Number of shows\",\n                       range = c(2, 8)) +\n  scale_color_gradientn(name = \"Number of shows\",\n                       colors = brewer.pal(9, \"YlOrRd\")) + \n  facet_wrap(~decade) +\n  theme_minimal() +\n  labs(title = \"U2 Concert Locations by Decade\",\n       x = \"Longitude\",\n       y = \"Latitude\") +\n  guides(color = guide_legend(order = 1),\n         size = guide_legend(order = 1)) +\n  theme(legend.position = \"right\",\n        legend.box = \"horizontal\") +\n  coord_fixed(1.3, \n             xlim = c(-180, 180),\n             ylim = c(-60, 90))\n\nprint(decades_plot)\n\n\n\n\n\n\n\n\n\n\nWorld map with zoom and popups using leaflet\nWith the leaflet package we have a world map here where you can zoom in and out, and you can click on the cities to see more info!\n\n# load libraries\nlibrary(ggplot2)\nlibrary(maps)\nlibrary(leaflet)\nlibrary(dplyr)\nlibrary(viridis)\n\n# Prepare the popup content\ncity_frequency_transformed &lt;- city_frequency_transformed %&gt;%\n  mutate(\n    popup_content = sprintf(\n      '&lt;div class=\"popup-content\"&gt;\n                &lt;h3&gt;%s, %s&lt;/h3&gt;\n                &lt;table&gt;\n                  &lt;tr&gt;&lt;td&gt;&lt;b&gt;Shows:&lt;/b&gt;&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n                  &lt;tr&gt;&lt;td&gt;&lt;b&gt;First show:&lt;/b&gt;&lt;/td&gt;&lt;td&gt;%s&lt;/td&gt;&lt;/tr&gt;\n                  &lt;tr&gt;&lt;td&gt;&lt;b&gt;Last show:&lt;/b&gt;&lt;/td&gt;&lt;td&gt;%s&lt;/td&gt;&lt;/tr&gt;\n                  &lt;tr&gt;&lt;td&gt;&lt;b&gt;Venues:&lt;/b&gt;&lt;/td&gt;&lt;td&gt;%s&lt;/td&gt;&lt;/tr&gt;\n                  &lt;tr&gt;&lt;td&gt;&lt;b&gt;Tours:&lt;/b&gt;&lt;/td&gt;&lt;td&gt;%s&lt;/td&gt;&lt;/tr&gt;\n                &lt;/table&gt;\n        &lt;/div&gt;',\n      city, country, show_count, first_show, last_show,\n      sapply(venues, function(x) paste(x, collapse = \", \")),\n      sapply(tours, function(x) paste(x, collapse = \", \"))\n    )\n  )\n\n# Create binned color scale matching the Shiny app\nbins &lt;- c(1, 3, 5, 10, 20, 50, Inf)\ncity_palette &lt;- colorBin(\"viridis\", domain = city_frequency_transformed$show_count, \n                        bins = bins, right = FALSE)\n\n# Create interactive map\nleaflet(city_frequency_transformed, width=\"100%\") %&gt;%\n  # Add different base map options \n  addProviderTiles(providers$CartoDB.Positron, group = \"Light\") %&gt;%\n  addProviderTiles(providers$CartoDB.DarkMatter, group = \"Dark\") %&gt;%\n  addProviderTiles(providers$Esri.WorldImagery, group = \"Satellite\") %&gt;%\n  \n  # Set default \n  setView(lng = 0, lat = 20, zoom = 2) %&gt;%\n  \n  # Add circles for cities with enhanced visibility\n  addCircleMarkers(\n    ~long, ~lat,\n    radius = ~pmax(5, log_shows * 3),  # Matching the min radius of 5 from Shiny app\n    popup = ~popup_content,\n    label = ~sprintf(\"%s: %d shows\", city, show_count),  # Matching the label format\n    labelOptions = labelOptions(textsize = \"12px\"),\n    color = ~city_palette(show_count),\n    fillOpacity = 0.7,\n    stroke = TRUE,\n    weight = 1,\n    opacity = 0.8\n  ) %&gt;%\n  \n  # Add layer control with Light as default\n  addLayersControl(\n    baseGroups = c(\"Light\", \"Dark\", \"Satellite\"),\n    options = layersControlOptions(collapsed = FALSE)\n  ) %&gt;%\n  \n  # Add legend \n  addLegend(\n    position = \"bottomright\",\n    pal = city_palette,\n    values = ~show_count,\n    title = \"Number of Shows\",\n    opacity = 0.7,\n    labFormat = labelFormat(digits = 0)\n  )",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "6. Visual Exploration"
    ]
  },
  {
    "objectID": "interactive-visual-apps.html",
    "href": "interactive-visual-apps.html",
    "title": "Interactive Visual Apps",
    "section": "",
    "text": "I created an interactive version of the world map so that the user can filter by tour and/or song. This was done with (Chang et al. 2024)R-Shiny and deployed to shinyapps.io at: U2 Tour Map.\nThe code of this Shiny app can be found in my GitHub repository at: https://github.com/vanleeuwen-hans/u2_tour_map",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "8. Interactive Visualizations"
    ]
  },
  {
    "objectID": "interactive-visual-apps.html#world-map-with-interactive-tour-and-song-filter-using-shiny",
    "href": "interactive-visual-apps.html#world-map-with-interactive-tour-and-song-filter-using-shiny",
    "title": "Interactive Visual Apps",
    "section": "",
    "text": "I created an interactive version of the world map so that the user can filter by tour and/or song. This was done with (Chang et al. 2024)R-Shiny and deployed to shinyapps.io at: U2 Tour Map.\nThe code of this Shiny app can be found in my GitHub repository at: https://github.com/vanleeuwen-hans/u2_tour_map",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "8. Interactive Visualizations"
    ]
  },
  {
    "objectID": "interactive-visual-apps.html#tour-setlist-alignment-with-interactive-tour-filter-using-shiny",
    "href": "interactive-visual-apps.html#tour-setlist-alignment-with-interactive-tour-filter-using-shiny",
    "title": "Interactive Visual Apps",
    "section": "Tour setlist alignment with interactive tour filter using Shiny",
    "text": "Tour setlist alignment with interactive tour filter using Shiny\nI created an interactive version of the setlist alignment so that the user select a tour and choose different number of shows. This was done with R-Shiny and deployed to shinyapps.io at: U2 Setlist Alignment.\nNote that this Shiny app hosted on the shinyapps.io free plan has a slow performance. The app works fast on my Mac but on shinyapps.io it is much slower, so be patient while it loads - it may take more than a minute. I am still lookig into code optimization to make it slower so a new version may be released in the future. The static plots of some tours can be found in this report: Multiple Setlist Alignment\nThe code of this Shiny app can be found in my GitHub repository at: https://github.com/vanleeuwen-hans/u2_setlist_alignment",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "8. Interactive Visualizations"
    ]
  },
  {
    "objectID": "ask-the-right-questions.html",
    "href": "ask-the-right-questions.html",
    "title": "Asking the Right Questions",
    "section": "",
    "text": "There is a U2 song from the early days that has a good point about asking the right questions:\n\n‚ÄúWe thought that we had the answers\nIt was the questions we had wrong‚Äù\n‚àº¬†11¬†O‚ÄôClock¬†Tick¬†Tock,¬†U2,¬†1980,¬†https://www.u2.com/lyrics/207\n\nMy questions that led to choosing this topic for the Capstone Project of the Google Data Analytics certification were coming from the often heard comments during U2 tours about the variety of songs played at different shows in the same tour. For a casual concert goer this is actually not a topic at all. But for the community of happily ‚Äòcrazy‚Äô U2 fans who go to multiple (and with that I mean many) concerts in the same tour it becomes a bit of a recurring discussion topic each tour:\n\n‚ÄòThe set-list is so fixed‚Äô\n‚ÄòThey really mixed it up last night!‚Äô\n‚ÄòWow! They played Bad tonight, they had not played that in years!‚Äô\n‚ÄòAren‚Äôt they getting bored playing the same songs again and again?‚Äô\n‚ÄòI love that they closed with 40, I had tears in my eyes‚Äô\n‚ÄòWhy don‚Äôt they play Acrobat for once? That song would be amazing live!‚Äô\n\nThese memories led me to the following questions or objectives for this data analytics project:\n\nHow do the tours over the last decades compare with regards to set-list variability?\nHow do the shows within the same tour compare with regard to the songs performed?\nHow can I visualize where certain songs were played world-wide?\nAre there any other trends or patterns visible in the data?\n\n\n\n\nEverything You Know is Wrong - U2 Innocence + Experience Tour, The O2, London, United Kingdom",
    "crumbs": [
      "Home",
      "Getting the Data",
      "1. Asking the Right Questions"
    ]
  },
  {
    "objectID": "multiple-setlist-alignment.html",
    "href": "multiple-setlist-alignment.html",
    "title": "Multiple Setlist Alignment",
    "section": "",
    "text": "Now we can dig a bit deeper, and see which songs are actually played in the set-lists of the shows within a tour. I have spent quite some time in experimenting with various biological sequence algorithms applied to this concert tour set-list alignment topic. For example, the CLUSTALW(Thompson, Gibson, and Higgins 2002) algorithms for multiple sequence alignment. The main challenge was to convert the non-biological sequence of a set-list to a biological sequence which is required for such algorithms. Eventually, I describe two approaches in this report:\n\ncustom R alignment code based on the Needleman-Wunsch(Murata 1990) algorithm\nhybrid R-bash-R process with the MAFFT(Katoh 2002) algorithm\n\nIn the plots below you can very well see the conserved blocks of the show, as well as the moments when there is more variability in the song they play each night.\nI also created an interactive Shiny app for this where you can select the tour of interest. See more info on the page Interactive Visualizations.",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "7. Multiple Setlist Alignment"
    ]
  },
  {
    "objectID": "multiple-setlist-alignment.html#tour-set-list-alignment",
    "href": "multiple-setlist-alignment.html#tour-set-list-alignment",
    "title": "Multiple Setlist Alignment",
    "section": "",
    "text": "Now we can dig a bit deeper, and see which songs are actually played in the set-lists of the shows within a tour. I have spent quite some time in experimenting with various biological sequence algorithms applied to this concert tour set-list alignment topic. For example, the CLUSTALW(Thompson, Gibson, and Higgins 2002) algorithms for multiple sequence alignment. The main challenge was to convert the non-biological sequence of a set-list to a biological sequence which is required for such algorithms. Eventually, I describe two approaches in this report:\n\ncustom R alignment code based on the Needleman-Wunsch(Murata 1990) algorithm\nhybrid R-bash-R process with the MAFFT(Katoh 2002) algorithm\n\nIn the plots below you can very well see the conserved blocks of the show, as well as the moments when there is more variability in the song they play each night.\nI also created an interactive Shiny app for this where you can select the tour of interest. See more info on the page Interactive Visualizations.",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "7. Multiple Setlist Alignment"
    ]
  },
  {
    "objectID": "multiple-setlist-alignment.html#load-custom-concertdata-package",
    "href": "multiple-setlist-alignment.html#load-custom-concertdata-package",
    "title": "Multiple Setlist Alignment",
    "section": "Load custom concertData package",
    "text": "Load custom concertData package\nFirst we load my custom concertData package where I organized all the functions to analyze the U2 concert data. This R package is available on my GitHub page at: https://github.com/vanleeuwen-hans/concertData.\n\nlibrary(devtools)\ndevtools::install_github(\"vanleeuwen-hans/concertData\")\nlibrary(concertData)",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "7. Multiple Setlist Alignment"
    ]
  },
  {
    "objectID": "multiple-setlist-alignment.html#load-the-u2data",
    "href": "multiple-setlist-alignment.html#load-the-u2data",
    "title": "Multiple Setlist Alignment",
    "section": "Load the u2data",
    "text": "Load the u2data\n\n# read the u2 concertData\nu2data &lt;- read_concertData_csv('u2data/u2data_all_shows_clean_final.csv')",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "7. Multiple Setlist Alignment"
    ]
  },
  {
    "objectID": "multiple-setlist-alignment.html#set-list-alignment-with-nw-approach",
    "href": "multiple-setlist-alignment.html#set-list-alignment-with-nw-approach",
    "title": "Multiple Setlist Alignment",
    "section": "Set-list alignment with NW approach",
    "text": "Set-list alignment with NW approach\nThe alignment plots below shows a first attempt of aligning setlists for each tour. It takes the 30 most representative shows for a tour, and then uses an alignment method to display the variation (or not) of songs played during the shows. The code handles insertions and deletions in the set-list sequences, similar to how DNA sequence alignment algorithms handle gaps. It uses dynamic programming to implement a variant of the Needleman-Wunsch(Murata 1990) algorithm.\n\n# Filter for specific tour\ntour_data &lt;- u2data[u2data$tour == \"U2 Vertigo Tour\", ]\n# Remove snippets\nno_snippets_data &lt;- concertData_remove_snippets(tour_data)\n# Remove shows with no setlist \nfiltered_data &lt;- concertData_remove_showsNoSetlist(no_snippets_data)\n\n# Process the songs to create the mapping of codes\ncodes_tour_songs &lt;- codify_tour_song_titles(filtered_data)\n\n# create alignments using a customly written multiple setlist aligment code\n# following the pairwise alignment approach of the Needleman-Wunsch algorithm\naligned_setlists &lt;- create_setlist_alignment(filtered_data, max_shows = 30)\n\n# create alignment data frame for downstream vizualisation\nalignment_data &lt;- format_alignment_data(aligned_setlists, codes_tour_songs, filtered_data)\n\n# get number of shows in the alignment\nnum_setlists &lt;- length(unique(alignment_data$showID))\n\n# Mapping the sequence characters to the tour_song_codes\nsong_code_lookup &lt;- codes_tour_songs[, c(\"hex_char\", \"four_letter_code\", \"song_title\")]\n\n# create vizualisation data object\nviz_data &lt;- create_setlist_viz_data(alignment_data, song_code_lookup, filtered_data)\n\n# Create legend for acronyms/short titles\nlegend_data &lt;- viz_data[!viz_data$is_gap, c(\"song_title\", \"four_letter_code\")]\nlegend_data &lt;- unique(legend_data)\nlegend_data &lt;- legend_data[order(legend_data$song_title), ]\nlegend_text &lt;- paste(legend_data$four_letter_code, \"=\", legend_data$song_title, collapse = \", \")\n\n# Create custom color scale that uses distinct colors for songs and white for gaps\nn_songs &lt;- length(unique(viz_data$song_title[!viz_data$is_gap]))\nsong_colors &lt;- create_distinct_palette(n_songs)\nnames(song_colors) &lt;- unique(viz_data$song_title[!viz_data$is_gap])\nsong_colors &lt;- c(song_colors, GAP = \"white\")\n\n# Get the tour name from filtered_data\n# Get a single showID from alignment_data\nsample_showID &lt;- alignment_data$showID[1]\n# Lookup the tour_name in filtered_data\ntour_name &lt;- unique(filtered_data$tour[filtered_data$showID == sample_showID])\n\n# plot the multiple sequence alignment of the tour setlists\n# load library\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(stringr)\n\n# Create a new column combining city and date\nviz_data$city_date &lt;- paste(viz_data$city, \"-\", as.character(viz_data$date))\n\n# Create a unique identifier for each show\nviz_data$show_id &lt;- seq_len(nrow(viz_data))\n\n# Convert city_date to a factor based on the original order in viz_data\nviz_data$city_date &lt;- factor(viz_data$city_date, levels = unique(viz_data$city_date[viz_data$show_id]))\n\n# Create main plot\nmain_plot &lt;- ggplot(viz_data, aes(x = position, y = city_date)) +\n  geom_tile(aes(fill = song_title), color = \"grey90\", linewidth = 0.5) +\n  geom_text(aes(label = ifelse(is_gap, \"\", four_letter_code)), \n            size = 1.5,\n            color = \"white\") +\n  scale_fill_manual(values = song_colors) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 7),\n        axis.text.y = element_text(size = 8),\n        plot.title = element_text(size = 12, hjust = 0.5),\n        plot.subtitle = element_text(size = 10, hjust = 0.5),\n        legend.position = \"none\",\n        panel.grid = element_blank()) +\n  labs(x = \"Song Position\", y = \"City - Show Date\",\n       title = paste(\"Setlist Alignment for\", tour_name),\n       subtitle = paste(\"Showing\", num_setlists, \"most representative setlists. Empty white cells indicate inserted/skipped songs\")\n  )\n\n# Create legend plot\nlegend_plot &lt;- ggplot() +\n  geom_text(aes(x = 0.5, y = 0.5, label = str_wrap(legend_text, width = 250)), \n           size = 2, hjust = 0.5) +\n  theme_void() + \n  theme(plot.margin = margin(t = 10))\n\n# Arrange plots together\ngrid.arrange(main_plot,\n             legend_plot,\n             ncol = 1,\n             heights = c(4, 1))",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "7. Multiple Setlist Alignment"
    ]
  },
  {
    "objectID": "multiple-setlist-alignment.html#multiple-setlist-alignment-with-mafft",
    "href": "multiple-setlist-alignment.html#multiple-setlist-alignment-with-mafft",
    "title": "Multiple Setlist Alignment",
    "section": "Multiple Setlist Alignment with MAFFT",
    "text": "Multiple Setlist Alignment with MAFFT\nI was not satisfied with the resulting alignments shown above, produced with the custom alignment code based on the Needleman-Wunsch algorithm. While exploring alternatives I discovered that the MAFFT(Katoh 2002) algorithm for multiple sequence alignment has an option ‚Äò‚Äìtext‚Äô mode that can calculate and create multiple sequence alignments for non-biological sequences (see this page from the MAFFT authors). In the R package ips there is a mafft wrapper function, so I installed and tried it out. However, this R implementation of mafft does not allow for the --text mode. Hence, I implemented the solution using both R and the command line version of mafft on my Mac. I could also wrap the command line actions and execute it from R, but I did not spend time on that, mainly because it would still create a challenging dependency in my R-package.\n\n# Filter for specific tour\ntour_data &lt;- u2data[u2data$tour == \"U2 Vertigo Tour\", ]\n# Remove snippets\nno_snippets_data &lt;- concertData_remove_snippets(tour_data)\n# Remove shows with no setlist \nfiltered_data &lt;- concertData_remove_showsNoSetlist(no_snippets_data)\n\n# Process the songs to create the mapping of codes\ncodes_tour_songs &lt;- codify_tour_song_titles(filtered_data)\n\n# Prepare all setlist sequences\nall_setlist_sequences &lt;- prepare_setlist_sequences(filtered_data, codes_tour_songs)\n\n# Find the most representative setlists\nrepresentative_setlists &lt;- find_most_representative_setlists(all_setlist_sequences, n_representatives = 30)\n\n# Create fasta-format sequences representing the set-lists of the representative shows\nfasta_mafft_output &lt;- create_setlist_fasta_mafft(representative_setlists)\nwriteLines(fasta_mafft_output, \"mafft/u2_setlists.hex\")\n\nNow we have the FASTA-like file with hex values that we can use as input for the multiple sequence alignment algorithm MAFFT. See explanation for this text mode version (non-biological sequences alignment) at: https://mafft.cbrc.jp/alignment/software/textcomparison.html\nFollowing the flow explained there, we convert the HEX file to ASCII code using the hex2mafftext command:\nhex2maffttext u2_setlists.hex &gt; u2_setlists.ASCII\nThe resulting file looks like:\nhead u2_setlists.ASCII\n&gt;showID1392\n,Q9R87,HL9M8CKVJMNf8I^_\n&gt;showID1408\n,Q9NM7,HL9M8CKVJROf8I^_\n&gt;showID1328\n,Q9E87,HL9M8CKVJG7f8I^_\n&gt;showID1320\n,Q9887,HL9M8CKVJGYf8I^_\n&gt;showID1325\n,Q9E87,HL9M8CKVJROf8I+^_\nThen we run the actual multiple sequence alignment with the command:\nmafft --text --clustalout u2_setlists.ASCII &gt; u2_setlists_mafft_alignment.ASCII\nThe output of the run:\nnthread = 0\nnthreadpair = 0\nnthreadtb = 0\nppenalty_ex = 0\nstacksize: 8192 kb\nnalphabets = 256\nGap Penalty = -1.53, +0.00, +0.00\n\n\n\nMaking a distance matrix ..\n    1 / 30\ndone.\n\nConstructing a UPGMA tree (efffree=0) ... \n   20 / 30\ndone.\n\nProgressive alignment 1/2... \nSTEP    20 / 29  d\nReallocating..done. *alloclen = 1048\nSTEP    29 / 29  h\ndone.\n\nMaking a distance matrix from msa.. \n    0 / 30\ndone.\n\nConstructing a UPGMA tree (efffree=1) ... \n   20 / 30\ndone.\n\nProgressive alignment 2/2... \nSTEP    28 / 29  d\nReallocating..done. *alloclen = 1048\nSTEP    29 / 29  h\ndone.\n\ndisttbfast (text) Version 7.526\nalg=A, model=Extended, 1.53, -0.00, -0.00, noshift, amax=0.0\n0 thread(s)\n\n\nStrategy:\n NW-NS-2 (Fast but rough)\n Progressive method (guide trees were built 2 times.)\n\nIf unsure which option to use, try 'mafft --auto input &gt; output'.\nFor more information, see 'mafft --help', 'mafft --man' and the mafft page.\n\nThe default gap scoring scheme has been changed in version 7.110 (2013 Oct).\nIt tends to insert more gaps into gap-rich regions than previous versions.\nTo disable this change, add the --leavegappyregion option\nThe output sequence alignment file looks like this:\nmore u2_setlists_mafft_alignment.ASCII\nCLUSTAL format alignment by MAFFT NW-NS-2 (v7.526)\n\n\nshowID1392      -,Q9R-87,HL9M8CKVJMN-f8I^_-\nshowID1408      -,Q9N-M7,HL9M8CKVJRO-f8I^_-\nshowID1328      -,Q9E-87,HL9M8CKVJG7-f8I^_-\nshowID1320      -,Q98-87,HL9M8CKVJ-GYf8I^_-\nshowID1325      -,Q9E-87,HL9M8CKVJRO-f8I+^_\nshowID1299      -,Q9D-8,-HL9M8\\KVJRO-Nf8^_-\nshowID1286      -,Q9R-88,HL9M8\\KVJRO-N8^_--\nshowID1282      -,Q9R-8,-HL9M8\\KVJRO-N8^_--\nshowID1339      -,Q9E--7,UL9M8CKVJMN-f7I^_-\nshowID1412      -,Q9D--7,UL9M8CKVJMN-f7I^_-\nshowID1327      -,Q9E-87,HL9M8CKVJ(--f8^_--\nshowID1271      QE899-,7,HL9M8CKVJRO-f8^_--\nshowID1267      QE899-,7,HL9M8CKVJRO-f8Q--\nshowID1269      QE899-,7,HL9M8CKVJRO-f8Q--\nshowID1270      QE899-,7,HL9M8CKVJRO-f8Q--\nshowID1393      -,Q9E-87,UL9M8CKVJMO-f8\\+-\nshowID1321      -,Q98-87,HL9M8CKVJLGYf8I^_-\nshowID1331      -,Q9E887,HL9M8CKVJ\\7-f8I^_-\nshowID1330      -,Q9E-87,HL9M8CKVJG7Bf8I^_-\nshowID1336      -,Q9N-M7,HL9M8CKVJ7Y-f8I^_-\nshowID1329      -,Q9-8@7,HL9M8CKVJ\\Y-f8+--\nshowID1259      QE89,-77,HL9M8CKVJRO-f8Q--\nshowID1266      QE899-,7,HL9M8CKVJRO-f8BQ-\nshowID1289      QE899-,7,HL9M8CKVJRO-f8BQ-\nshowID1435      -,Q9E--9,DL9M8CKVJON-f8%:-\nshowID1281      -,Q9R-8,9HL9M8\\KVJRO-N8^_--\nshowID1305      -,Q9R-8,9HL9M8\\KVJRO-N8^_--\nshowID1436      -,Q9E-9,7%L9M8CKVJRO-f82:-\nshowID1322      -,Q988F7,HL9M8CKVJG7-f8^_--\nshowID1284      -,Q9D-8,-HL9M8\\KVJRO-N87+-\n                   *      **** ***        \nNow we can visualize this multiple set list alignment.\n\n# libraries\nlibrary(dplyr)\nlibrary(stringr)\n\n# Get a data frame from the mafft clustal output\nalignment_data &lt;- read_mafft_clustal_alignment(\"mafft/u2_setlists_mafft_alignment.ASCII\")\n\n# get number of shows in the alignment\nnum_setlists &lt;- length(unique(alignment_data$showID))\n\n# Mapping the sequence characters to the tour_song_codes\nsong_code_lookup &lt;- codes_tour_songs[, c(\"hex_char\", \"four_letter_code\", \"song_title\")]\n\n# create vizualisation data object\nviz_data &lt;- create_setlist_viz_data(alignment_data, song_code_lookup, filtered_data)\n\n# Create legend for acronyms/short titles\nlegend_data &lt;- viz_data[!viz_data$is_gap, c(\"song_title\", \"four_letter_code\")]\nlegend_data &lt;- unique(legend_data)\nlegend_data &lt;- legend_data[order(legend_data$song_title), ]\nlegend_text &lt;- paste(legend_data$four_letter_code, \"=\", legend_data$song_title, collapse = \", \")\n\n# Create custom color scale that uses distinct colors for songs and white for gaps\nn_songs &lt;- length(unique(viz_data$song_title[!viz_data$is_gap]))\nsong_colors &lt;- create_distinct_palette(n_songs)\nnames(song_colors) &lt;- unique(viz_data$song_title[!viz_data$is_gap])\nsong_colors &lt;- c(song_colors, GAP = \"white\")\n\n# Get the tour name from filtered_data\n# Get a single showID from alignment_data\nsample_showID &lt;- alignment_data$showID[1]\n# Lookup the tour_name in filtered_data\ntour_name &lt;- unique(filtered_data$tour[filtered_data$showID == sample_showID])\n\n# plot the multiple sequence alignment of the tour setlists\n# load library\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n# Create a new column combining city and date\nviz_data$city_date &lt;- paste(viz_data$city, \"-\", as.character(viz_data$date))\n\n# Create a unique identifier for each show\nviz_data$show_id &lt;- seq_len(nrow(viz_data))\n\n# Convert city_date to a factor based on the original order in viz_data\nviz_data$city_date &lt;- factor(viz_data$city_date, levels = unique(viz_data$city_date[viz_data$show_id]))\n\n# Create main plot\nmain_plot &lt;- ggplot(viz_data, aes(x = position, y = city_date)) +\n  geom_tile(aes(fill = song_title), color = \"grey90\", linewidth = 0.5) +\n  geom_text(aes(label = ifelse(is_gap, \"\", four_letter_code)), \n            size = 1.5,\n            color = \"white\") +\n  scale_fill_manual(values = song_colors) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 7),\n        axis.text.y = element_text(size = 8),\n        plot.title = element_text(size = 12, hjust = 0.5),\n        plot.subtitle = element_text(size = 10, hjust = 0.5),\n        legend.position = \"none\",\n        panel.grid = element_blank()) +\n  labs(x = \"Song Position\", y = \"City - Show Date\",\n       title = paste(\"Setlist Alignment for\", tour_name),\n       subtitle = paste(\"Showing\", num_setlists, \"most representative setlists. Empty white cells indicate inserted/skipped songs\")\n  )\n\n# Create legend plot\nlegend_plot &lt;- ggplot() +\n  geom_text(aes(x = 0.5, y = 0.5, label = str_wrap(legend_text, width = 250)), \n           size = 2, hjust = 0.5) +\n  theme_void() + \n  theme(plot.margin = margin(t = 10))\n\n# Arrange plots together\ngrid.arrange(main_plot,\n             legend_plot,\n             ncol = 1,\n             heights = c(4, 1))",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "7. Multiple Setlist Alignment"
    ]
  },
  {
    "objectID": "multiple-setlist-alignment.html#distance-tree-of-aligned-setlists",
    "href": "multiple-setlist-alignment.html#distance-tree-of-aligned-setlists",
    "title": "Multiple Setlist Alignment",
    "section": "Distance tree of aligned setlists",
    "text": "Distance tree of aligned setlists\nAnother way to display the relatedness of setlists is to use a distance tree, often used for biological sequences, producing so called phylogenetic trees. The (Xu et al. 2022)ggtree and (Paradis and Schliep 2018)ape packages were used for the plots.\n\nlibrary(dplyr)\nlibrary(seqinr)\nlibrary(ape)\nlibrary(ggplot2)\nlibrary(ggtree)\n\n# Get a data frame from the mafft clustal output\nalignment_data &lt;- read_mafft_clustal_alignment(\"mafft/u2_setlists_mafft_alignment.ASCII\")\n# Convert data frame to list which is needed for downstream distance tree analysis\nsequences &lt;- setNames(as.list(alignment_data$sequence), paste0(\"showID\", alignment_data$showID))\n\n# Calculate distance matrix\ndist_matrix &lt;- calculate_distance_matrix(sequences)\n# Convert to dist object\nsetlist_dist &lt;- as.dist(dist_matrix)\n# Construct the tree\nsetlist_tree &lt;- nj(setlist_dist)\n\n# Collect show info\nshow_info &lt;- unique(filtered_data[, c(\"showID\", \"city\", \"date\", \"country\", \"leg\")])\nshow_info$city_date &lt;- paste(show_info$city, format(show_info$date, \"%Y-%m-%d\"), sep = \" - \")\n\n# create tree labels in the format 'City YYYY-MM-DD'\nnew_labels &lt;- create_city_date_tree_labels(filtered_data, setlist_tree, show_info)\n# Modify tree labels \nsetlist_tree$tip.label &lt;- new_labels\n\n# create standard tree plot\ntree_plot &lt;- create_ggtree_plot(setlist_tree)\n# Display the plot\nprint(tree_plot)\n\n\n\n\n\n\n\n# Create the tree plot with colors based on country\nplot_country &lt;- create_ggtree_plot_colored(setlist_tree, show_info, color_by = \"country\")\nprint(plot_country)\n\n\n\n\n\n\n\n# Create the tree plot with colors based on leg\nplot_leg &lt;- create_ggtree_plot_colored(setlist_tree, show_info, color_by = \"leg\")\nprint(plot_leg)",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "7. Multiple Setlist Alignment"
    ]
  },
  {
    "objectID": "check-and-initial-exploration-of-the-data.html",
    "href": "check-and-initial-exploration-of-the-data.html",
    "title": "Initial Data Exploration",
    "section": "",
    "text": "I performed an initial data exploration, comparing some numbers with the U2 tour statistics listed on the u2gigs.com site page: https://www.u2gigs.com/tourdb-stats.html. Remember, that is the source of my data.\n\n# load required libraries\nlibrary(dplyr)\nlibrary(readr)\n\n# read file\nu2data &lt;- read_csv(\"u2data/archive/u2data_all_shows_clean.csv\")\n\n\n# number of countries where U2 played shows\ncat(\"Number of countries: \", nrow(unique(u2data[,c('country')])), \"\\n\")\n\nNumber of countries:  48 \n\n\nThe number at u2gigs.com (October 2024) is 49 (https://www.u2gigs.com/all-countries.html). We see here that in my data there is 1 country less compared to what is listed at u2gigs.com. Now let‚Äôs check the number of different songs played over all shows.\n\n# number of different songs played by U2 at the shows\ncat(\"Number of songs played at the shows: \", nrow(unique(u2data[,c('song_title')])), \"\\n\")\n\nNumber of songs played at the shows:  993 \n\n\nThe number at u2gigs.com (October 2024) is 994 (https://www.u2gigs.com/most-played-songs.html). We see here that in my data there is 1 song less compared to what is listed at u2gigs.com. Now let‚Äôs check number of shows played in some cities.\n\n# cities with most shows played (only top 5 plus Amsterdam)\naggregate(data=u2data,  showID ~ city, subset = city %in% c('Dublin', 'New York', 'London', 'Las Vegas', 'Los Angeles', 'Amsterdam'),  function(x) length(unique(x))) %&gt;%\n  arrange(.,desc(showID))\n\n         city showID\n1      Dublin    145\n2    New York    131\n3      London    100\n4   Las Vegas     53\n5 Los Angeles     50\n6   Amsterdam     19\n\n\nWhen we compare that with u2gigs.com (Oct 2024 screen shot below) we see that the numbers are not the same.\n\n\n\nNumber of shows per city - source U2gigs.com - October 2024.\n\n\nLet‚Äôs dive into the Amsterdam shows where my data contains 19 and u2gigs.com lists 23.\n\n# shows done in Amsterdam venues\namsterdam_data &lt;- subset(u2data, city == 'Amsterdam', select = c(\"showID\",\"city\",\"venue\", \"tour\"))\naggregate(data=amsterdam_data, showID ~ tour + venue, function(x) length(unique(x))) %&gt;%\n  arrange(.,desc(tour))\n\n                             tour                  venue showID\n1                 U2 Vertigo Tour        Amsterdam ArenA      3\n2                U2 Various Dates Muziekgebouw aan 't IJ      1\n3                U2 Various Dates               Paradiso      1\n4                U2 Various Dates             Westerunie      1\n5                 U2 October Tour               Paradiso      1\n6                U2 Lovetown Tour         Rai Europa Hal      1\n7        U2 Joshua Tree Tour 2017        Amsterdam ArenA      2\n8  U2 Innocence + Experience Tour             Ziggo Dome      4\n9  U2 Experience + Innocence Tour             Ziggo Dome      2\n10                    U2 Boy Tour           The Milkyway      1\n11                   U2 360¬∞ Tour        Amsterdam ArenA      2\n\n\nThe u2gigs.com info:\n\n\n\nShows in Amsterdam - source U2gigs.com - October 2024.\n\n\nThe 4 shows that are missing in my data are:\n\n1981-02-11: Unknown Bar - Amsterdam, Netherlands\n1981-02-11: Paradiso - Amsterdam, Netherlands\n1989-12-19: Rai Europa Hal - Amsterdam, Netherlands\n1989-12-20: Rai Europa Hal - Amsterdam, Netherlands\n\nChecking these on u2gigs.com, we see that these are all shows that do not have a set list (no played songs listed), while all the other 19 Amsterdam shows do have a set list. Confirming that these are missing from my data:\n\n# check Amsterdam shows that were missing before\nmissing_Amsterdam_shows &lt;- subset(u2data, date == '1981-02-11' | date == '1989-12-19' | date == '1989-12-20', select = c(\"date\",\"venue\"))\nprint(missing_Amsterdam_shows)\n\n# A tibble: 0 √ó 2\n# ‚Ñπ 2 variables: date &lt;date&gt;, venue &lt;chr&gt;\n\n\nI concluded that the shows without set lists had not been stored by my scraping code. Indeed, when I went back to check my scraping code I saw where the issue was. Thus, I adapted the code to retrieve those 297 shows without set list, and then added them to the final data file:\nFirst create new file with header:\nhead -n 1 u2data_all_shows_clean.csv &gt; u2data_all_shows_clean_final.csv\nThen concatenate content from 3 data files into the new file (skipping headers):\ntail -n +2 -q u2data_all_shows_clean.csv &gt;&gt; u2data_all_shows_clean_final.csv \ntail -n +2 -q u2analytics_data_nosetlistshows-dates.csv &gt;&gt; u2data_all_shows_clean_final.csv",
    "crumbs": [
      "Home",
      "Getting the Data",
      "4. Initial Data Exploration"
    ]
  },
  {
    "objectID": "check-and-initial-exploration-of-the-data.html#comparing-my-data-and-numbers-with-u2gigs.com",
    "href": "check-and-initial-exploration-of-the-data.html#comparing-my-data-and-numbers-with-u2gigs.com",
    "title": "Initial Data Exploration",
    "section": "",
    "text": "I performed an initial data exploration, comparing some numbers with the U2 tour statistics listed on the u2gigs.com site page: https://www.u2gigs.com/tourdb-stats.html. Remember, that is the source of my data.\n\n# load required libraries\nlibrary(dplyr)\nlibrary(readr)\n\n# read file\nu2data &lt;- read_csv(\"u2data/archive/u2data_all_shows_clean.csv\")\n\n\n# number of countries where U2 played shows\ncat(\"Number of countries: \", nrow(unique(u2data[,c('country')])), \"\\n\")\n\nNumber of countries:  48 \n\n\nThe number at u2gigs.com (October 2024) is 49 (https://www.u2gigs.com/all-countries.html). We see here that in my data there is 1 country less compared to what is listed at u2gigs.com. Now let‚Äôs check the number of different songs played over all shows.\n\n# number of different songs played by U2 at the shows\ncat(\"Number of songs played at the shows: \", nrow(unique(u2data[,c('song_title')])), \"\\n\")\n\nNumber of songs played at the shows:  993 \n\n\nThe number at u2gigs.com (October 2024) is 994 (https://www.u2gigs.com/most-played-songs.html). We see here that in my data there is 1 song less compared to what is listed at u2gigs.com. Now let‚Äôs check number of shows played in some cities.\n\n# cities with most shows played (only top 5 plus Amsterdam)\naggregate(data=u2data,  showID ~ city, subset = city %in% c('Dublin', 'New York', 'London', 'Las Vegas', 'Los Angeles', 'Amsterdam'),  function(x) length(unique(x))) %&gt;%\n  arrange(.,desc(showID))\n\n         city showID\n1      Dublin    145\n2    New York    131\n3      London    100\n4   Las Vegas     53\n5 Los Angeles     50\n6   Amsterdam     19\n\n\nWhen we compare that with u2gigs.com (Oct 2024 screen shot below) we see that the numbers are not the same.\n\n\n\nNumber of shows per city - source U2gigs.com - October 2024.\n\n\nLet‚Äôs dive into the Amsterdam shows where my data contains 19 and u2gigs.com lists 23.\n\n# shows done in Amsterdam venues\namsterdam_data &lt;- subset(u2data, city == 'Amsterdam', select = c(\"showID\",\"city\",\"venue\", \"tour\"))\naggregate(data=amsterdam_data, showID ~ tour + venue, function(x) length(unique(x))) %&gt;%\n  arrange(.,desc(tour))\n\n                             tour                  venue showID\n1                 U2 Vertigo Tour        Amsterdam ArenA      3\n2                U2 Various Dates Muziekgebouw aan 't IJ      1\n3                U2 Various Dates               Paradiso      1\n4                U2 Various Dates             Westerunie      1\n5                 U2 October Tour               Paradiso      1\n6                U2 Lovetown Tour         Rai Europa Hal      1\n7        U2 Joshua Tree Tour 2017        Amsterdam ArenA      2\n8  U2 Innocence + Experience Tour             Ziggo Dome      4\n9  U2 Experience + Innocence Tour             Ziggo Dome      2\n10                    U2 Boy Tour           The Milkyway      1\n11                   U2 360¬∞ Tour        Amsterdam ArenA      2\n\n\nThe u2gigs.com info:\n\n\n\nShows in Amsterdam - source U2gigs.com - October 2024.\n\n\nThe 4 shows that are missing in my data are:\n\n1981-02-11: Unknown Bar - Amsterdam, Netherlands\n1981-02-11: Paradiso - Amsterdam, Netherlands\n1989-12-19: Rai Europa Hal - Amsterdam, Netherlands\n1989-12-20: Rai Europa Hal - Amsterdam, Netherlands\n\nChecking these on u2gigs.com, we see that these are all shows that do not have a set list (no played songs listed), while all the other 19 Amsterdam shows do have a set list. Confirming that these are missing from my data:\n\n# check Amsterdam shows that were missing before\nmissing_Amsterdam_shows &lt;- subset(u2data, date == '1981-02-11' | date == '1989-12-19' | date == '1989-12-20', select = c(\"date\",\"venue\"))\nprint(missing_Amsterdam_shows)\n\n# A tibble: 0 √ó 2\n# ‚Ñπ 2 variables: date &lt;date&gt;, venue &lt;chr&gt;\n\n\nI concluded that the shows without set lists had not been stored by my scraping code. Indeed, when I went back to check my scraping code I saw where the issue was. Thus, I adapted the code to retrieve those 297 shows without set list, and then added them to the final data file:\nFirst create new file with header:\nhead -n 1 u2data_all_shows_clean.csv &gt; u2data_all_shows_clean_final.csv\nThen concatenate content from 3 data files into the new file (skipping headers):\ntail -n +2 -q u2data_all_shows_clean.csv &gt;&gt; u2data_all_shows_clean_final.csv \ntail -n +2 -q u2analytics_data_nosetlistshows-dates.csv &gt;&gt; u2data_all_shows_clean_final.csv",
    "crumbs": [
      "Home",
      "Getting the Data",
      "4. Initial Data Exploration"
    ]
  },
  {
    "objectID": "check-and-initial-exploration-of-the-data.html#confirm-data-after-adding-the-shows-without-setlist",
    "href": "check-and-initial-exploration-of-the-data.html#confirm-data-after-adding-the-shows-without-setlist",
    "title": "Initial Data Exploration",
    "section": "Confirm data after adding the shows without setlist",
    "text": "Confirm data after adding the shows without setlist\nAfter adding the shows without set list I loaded and explored the data again.\n\n# load required libraries\nlibrary(dplyr)\nlibrary(readr)\n\n# read data\n# note: file name was changed after an issue with city names was detected\nu2data &lt;- read_csv('u2data/archive/u2data_all_shows_clean_final_incorrect_cities.csv')\n\n\n# number of countries where U2 played shows\ncat(\"Number of countries: \", nrow(unique(u2data[,c('country')])), \"\\n\")\n\nNumber of countries:  49 \n\n\nRemember, from earlier, that the number of countries listed at u2gigs.com is 49. So, this is now correct in my data. Now let‚Äôs look at the number of different songs played again.\n\n# number of different songs played by U2 at the shows\ncat(\"Number of songs played at the shows: \", nrow(unique(u2data[,c('song_title')])), \"\\n\")\n\nNumber of songs played at the shows:  994 \n\n\nThe number at u2gigs.com (October 2024) is 994 (https://www.u2gigs.com/most-played-songs.html), which is the same as in my data.\n\n# cities with most shows played (only top 5 plus Amsterdam)\naggregate(data=u2data,  showID ~ city, subset = city %in% c('Dublin', 'New York', 'London', 'Las Vegas', 'Los Angeles', 'Amsterdam'),  function(x) length(unique(x))) %&gt;%\n  arrange(.,desc(showID))\n\n         city showID\n1      Dublin    202\n2    New York    146\n3      London    125\n4   Las Vegas     54\n5 Los Angeles     53\n6   Amsterdam     23\n\n\nThis still does not fully coincide with the u2gigs.com statistics:\n\n\n\nNumber of shows per city - source U2gigs.com - October 2024.\n\n\nI‚Äôll look at that in a bit but first let‚Äôs check the Amsterdam shows again.\n\n# shows done in Amsterdam venues\namsterdam_data &lt;- subset(u2data, city == 'Amsterdam', select = c(\"showID\",\"city\",\"venue\", \"tour\"))\naggregate(data=amsterdam_data, showID ~ tour + venue, function(x) length(unique(x))) %&gt;%\n  arrange(.,desc(tour))\n\n                             tour                  venue showID\n1                 U2 Vertigo Tour        Amsterdam ArenA      3\n2                U2 Various Dates Muziekgebouw aan 't IJ      1\n3                U2 Various Dates               Paradiso      1\n4                U2 Various Dates            Unknown Bar      1\n5                U2 Various Dates             Westerunie      1\n6                 U2 October Tour               Paradiso      1\n7                U2 Lovetown Tour         Rai Europa Hal      3\n8        U2 Joshua Tree Tour 2017        Amsterdam ArenA      2\n9  U2 Innocence + Experience Tour             Ziggo Dome      4\n10 U2 Experience + Innocence Tour             Ziggo Dome      2\n11                    U2 Boy Tour               Paradiso      1\n12                    U2 Boy Tour           The Milkyway      1\n13                   U2 360¬∞ Tour        Amsterdam ArenA      2\n\n\nThe 4 shows that were missing earlier now do appear in my data.\n\n# check Amsterdam shows that were missing before\nmissing_Amsterdam_shows &lt;- subset(u2data, date == '1981-02-11' | date == '1989-12-19' | date == '1989-12-20', select = c(\"date\", \"venue\"))\nprint(missing_Amsterdam_shows)\n\n# A tibble: 4 √ó 2\n  date       venue         \n  &lt;date&gt;     &lt;chr&gt;         \n1 1981-02-11 Paradiso      \n2 1989-12-19 Rai Europa Hal\n3 1989-12-20 Rai Europa Hal\n4 1981-02-11 Unknown Bar",
    "crumbs": [
      "Home",
      "Getting the Data",
      "4. Initial Data Exploration"
    ]
  },
  {
    "objectID": "check-and-initial-exploration-of-the-data.html#fixing-incorrect-city-and-venue-names",
    "href": "check-and-initial-exploration-of-the-data.html#fixing-incorrect-city-and-venue-names",
    "title": "Initial Data Exploration",
    "section": "Fixing incorrect city and venue names",
    "text": "Fixing incorrect city and venue names\nAs mentioned, the number of shows in some cities did not fully match the number listed at u2gigs.com. I explored this by obtaining a list of all cities listed at u2gigs.com (https://www.u2gigs.com/all-locations-city.html), and by getting a list of unique city names in my data:\n\n# get and print unique cities\nprint(unique(u2data[,c('city')]))\n\n# A tibble: 410 √ó 1\n   city      \n   &lt;chr&gt;     \n 1 Dublin    \n 2 Glasgow   \n 3 Rotterdam \n 4 Amsterdam \n 5 New York  \n 6 Washington\n 7 Belfast   \n 8 Drammen   \n 9 Edinburgh \n10 Stockholm \n# ‚Ñπ 400 more rows\n\n\nI took the list of cities from both sources in Excel and identified the different city entries. I observed 5 strange city entries in my data:\n\narne\nelin\nenis\nlosters\nrent\n\nI then retrieved more info about these entries in my data, including the showID so that I could manually check these shows at u2gigs.com.\n\n# check cities not listed at u2gigs.com\n\nextra_cities &lt;- subset(u2data, city == 'arne' | city == 'elin' | city == 'enis' | city == 'losters' | city == 'rent', select = c(\"showID\", \"country\", \"city\", \"date\",\"venue\"))\nprint(extra_cities)\n\n# A tibble: 247 √ó 5\n   showID country city  date       venue                       \n    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt; &lt;date&gt;     &lt;chr&gt;                       \n 1    978 France  arne  1980-12-04 Pavillon Baltard - Nogent-su\n 2    978 France  arne  1980-12-04 Pavillon Baltard - Nogent-su\n 3    978 France  arne  1980-12-04 Pavillon Baltard - Nogent-su\n 4    978 France  arne  1980-12-04 Pavillon Baltard - Nogent-su\n 5    978 France  arne  1980-12-04 Pavillon Baltard - Nogent-su\n 6    978 France  arne  1980-12-04 Pavillon Baltard - Nogent-su\n 7    978 France  arne  1980-12-04 Pavillon Baltard - Nogent-su\n 8    978 France  arne  1980-12-04 Pavillon Baltard - Nogent-su\n 9    978 France  arne  1980-12-04 Pavillon Baltard - Nogent-su\n10    978 France  arne  1980-12-04 Pavillon Baltard - Nogent-su\n# ‚Ñπ 237 more rows\n\n\nI concluded that the following correct city names corresponded to these entries:\n\narne -&gt; Nogent-sur-Marne\nelin -&gt; Vaulx-en-Velin\nenis -&gt; Saint-Denis\nlosters -&gt; Davos-Klosters\nrent -&gt; Stoke-on-Trent\n\nAll these issues were caused by a flaw in the scraping code when using a regular expression to separate the venue from the city. The issue occurred either when dashes ‚Äò-‚Äô were present in the city name or in the venue name.\nI corrected this with the following commands in the data file:\n# Step 1: change \"Pavillon Baltard - Nogent-su\",\"arne\" to \"Pavillon Baltard\",\"Nogent-sur-Marne\"\n# first check pattern\ngrep '\\\"Pavillon Baltard - Nogent-su\\\",\\\"arne\\\"' u2data_all_shows_clean_final.csv | wc -l\n      12\n# now replace\nawk '{gsub(/\\\"Pavillon Baltard - Nogent-su\\\",\\\"arne\\\"/,\"\\\"Pavillon Baltard\\\",\\\"Nogent-sur-Marne\\\"\")}1' u2data_all_shows_clean_final.csv &gt; u2data_all_shows_clean_final2.csv\n# check result\ngrep '\\\"Pavillon Baltard - Nogent-su\\\",\\\"arne\\\"' u2data_all_shows_clean_final2.csv | wc -l\n       0\ngrep '\\\"Pavillon Baltard\\\",\\\"Nogent-sur-Marne\\\"' u2data_all_shows_clean_final2.csv | wc -l\n      12\n\n\n# Step 2: change \"Ecole Nationale des Travaux Publics - Vaulx-e\",\"elin\" to \"Ecole Nationale des Travaux Public\",\"Vaulx-en-Velin\"\n# first check pattern\ngrep '\\\"Ecole Nationale des Travaux Publics - Vaulx-e\\\",\\\"elin\\\"' u2data_all_shows_clean_final2.csv | wc -l\n      1\n# now replace\nawk '{gsub(/\\\"Ecole Nationale des Travaux Publics - Vaulx-e\\\",\\\"elin\\\"/,\"\\\"Ecole Nationale des Travaux Publics\\\",\\\"Vaulx-en-Velin\\\"\")}1' u2data_all_shows_clean_final2.csv &gt; u2data_all_shows_clean_final3.csv\n# check result\ngrep '\\\"Ecole Nationale des Travaux Publics - Vaulx-e\\\",\\\"elin\\\"' u2data_all_shows_clean_final3.csv | wc -l\n      0\ngrep '\\\"Ecole Nationale des Travaux Publics\\\",\\\"Vaulx-en-Velin\\\"' u2data_all_shows_clean_final3.csv | wc -l\n      1\n\n# Step 3: change \"Stade de France - Sain\",\"enis\" to \"Stade de France\",\"Saint-Denis\"\n# first check pattern\ngrep '\\\"Stade de France - Sain\\\",\\\"enis\\\"' u2data_all_shows_clean_final3.csv | wc -l\n      232\n# now replace\nawk '{gsub(/\\\"Stade de France - Sain\\\",\\\"enis\\\"/,\"\\\"Stade de France\\\",\\\"Saint-Denis\\\"\")}1' u2data_all_shows_clean_final3.csv &gt; u2data_all_shows_clean_final4.csv\n# check result\ngrep '\\\"Stade de France - Sain\\\",\\\"enis\\\"' u2data_all_shows_clean_final4.csv | wc -l\n      0\ngrep '\\\"Stade de France\",\"Saint-Denis\\\"' u2data_all_shows_clean_final4.csv | wc -l\n      1\n\n# Step 4: change \"World Economic Forum - Davo\",\"losters\" to \"World Economic Forum\",\"Davos-Klosters\"\n# first check pattern\ngrep '\\\"World Economic Forum - Davo\\\",\\\"losters\\\"' u2data_all_shows_clean_final4.csv | wc -l\n      1\n# now replace\nawk '{gsub(/\\\"World Economic Forum - Davo\\\",\\\"losters\\\"/,\"\\\"World Economic Forum\\\",\\\"Davos-Klosters\\\"\")}1' u2data_all_shows_clean_final4.csv &gt; u2data_all_shows_clean_final5.csv\n# check result\ngrep '\\\"World Economic Forum - Davo\\\",\\\"losters\\\"' u2data_all_shows_clean_final5.csv | wc -l\n      0\ngrep '\\\"World Economic Forum\",\"Davos-Klosters\\\"' u2data_all_shows_clean_final5.csv | wc -l\n      1 \n\n\n# Step 5: change \"King's Hall - Stoke-o\",\"rent\" to \"King's Hall\",\"Stoke-on-Trent\"\n# first check pattern\ngrep \"\\\"King\\'s Hall - Stoke-o\\\",\\\"rent\\\"\" u2data_all_shows_clean_final5.csv | wc -l\n      1\n# now replace \n# note that \\047 is used to match the single quote\nawk '{gsub(/\\\"King\\047s Hall - Stoke-o\\\",\\\"rent\\\"/,\"\\\"King\\047s Hal\\\",\\\"Stoke-on-Trent\\\"\")}1' u2data_all_shows_clean_final5.csv &gt; u2data_all_shows_clean_final6.csv\n# check result\ngrep \"\\\"King\\'s Hall - Stoke-o\\\",\\\"rent\\\"\" u2data_all_shows_clean_final6.csv | wc -l | wc -l\n      0\ngrep \"\\\"King's Hal\\\",\\\"Stoke-on-Trent\\\"\" u2data_all_shows_clean_final6.csv | wc -l\n      1 \n\n# file house keeping\nmv u2data_all_shows_clean_final.csv archive/u2data_all_shows_clean_final_incorrect_cities.csv\nmv u2data_all_shows_clean_final2.csv archive/u2data_all_shows_clean_final2.csv\nmv u2data_all_shows_clean_final3.csv archive/u2data_all_shows_clean_final3.csv\nmv u2data_all_shows_clean_final4.csv archive/u2data_all_shows_clean_final4.csv\nmv u2data_all_shows_clean_final5.csv archive/u2data_all_shows_clean_final5.csv\nmv u2data_all_shows_clean_final6.csv u2data_all_shows_clean_final.csv",
    "crumbs": [
      "Home",
      "Getting the Data",
      "4. Initial Data Exploration"
    ]
  },
  {
    "objectID": "check-and-initial-exploration-of-the-data.html#fixing-additional-issues-in-the-song_lyrics-field",
    "href": "check-and-initial-exploration-of-the-data.html#fixing-additional-issues-in-the-song_lyrics-field",
    "title": "Initial Data Exploration",
    "section": "Fixing additional issues in the song_lyrics field",
    "text": "Fixing additional issues in the song_lyrics field\nLoading the file with read_csv() still produced some error messages in the song_lyrics field. In the affected lines I observed three potential issues: ;‚Äú,‚Äù;, ‚Äú. This was fixed as follows:\n# Step 1: fix \";\ngrep '\";' u2data_all_shows_clean_final.csv | wc -l\n       8\nawk '{gsub(/\\\";/,\"\")}1' u2data_all_shows_clean_final.csv &gt; u2data_all_shows_clean_final7.csv\ngrep '\";' u2data_all_shows_clean_final7.csv | wc -l\n       0\n\n# Step 2: fix ;\"\ngrep ';\"' u2data_all_shows_clean_final.csv | wc -l\n       8\nawk '{gsub(/;\\\"/,\"\")}1' u2data_all_shows_clean_final7.csv &gt; u2data_all_shows_clean_final8.csv\ngrep ';\"' u2data_all_shows_clean_final8.csv | wc -l\n       0\n\n\n# Step 3: fix \\\"\ngrep '\\\\\"' u2data_all_shows_clean_final.csv | wc -l\n      30\nawk '{gsub(/\\\\\"/,\"\\\"\")}1' u2data_all_shows_clean_final8.csv &gt; u2data_all_shows_clean_final9.csv\ngrep '\\\\\"' u2data_all_shows_clean_final9.csv | wc -l\n       0\n# file house keeping       \nmv u2data_all_shows_clean_final.csv archive/u2data_all_shows_clean_final_incorrect_cities_more_issues.csv\nmv u2data_all_shows_clean_final7.csv archive/u2data_all_shows_clean_final7.csv\nmv u2data_all_shows_clean_final8.csv archive/u2data_all_shows_clean_final8.csv\nmv u2data_all_shows_clean_final9.csv u2data_all_shows_clean_final.csv",
    "crumbs": [
      "Home",
      "Getting the Data",
      "4. Initial Data Exploration"
    ]
  },
  {
    "objectID": "check-and-initial-exploration-of-the-data.html#final-data-loading-of-fixed-data",
    "href": "check-and-initial-exploration-of-the-data.html#final-data-loading-of-fixed-data",
    "title": "Initial Data Exploration",
    "section": "Final data loading of fixed data",
    "text": "Final data loading of fixed data\nNow the fixed data file was loaded in R with read_CSV() successfully:\n\n# load required libraries\nlibrary(dplyr)\nlibrary(readr)\n\n# read file\n# normally the following file would be read\n# however after this \"final\" file was loaded one more issue was detected\n# this issue is referred to as the 'Rosemont duplication issue'\n# this is explained on the 'Basic Statistics U2 Concerts' page of this report\n# u2data &lt;- read_csv('u2data/u2data_all_shows_clean_final.csv')\n\n# for the sake of the rmarkdown report \n# read the following file where the Rosemont duplication was not fixed yet\nu2data &lt;- read_csv('u2data/archive/u2data_all_shows_clean_final_rosemontdup.csv')\n\nRows: 39674 Columns: 15\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr  (10): tour, leg, venue, city, state, country, song_title, show_url, son...\ndbl   (2): showID, song_position\nlgl   (2): snippet, encore\ndate  (1): date\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# see the structure of the data frame\nstr(u2data)\n\nspc_tbl_ [39,674 √ó 15] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ showID       : num [1:39674] 1 1 1 1 1 1 1 1 2 2 ...\n $ tour         : chr [1:39674] \"U2 Early Days\" \"U2 Early Days\" \"U2 Early Days\" \"U2 Early Days\" ...\n $ leg          : chr [1:39674] \"Early Days - Irish Shows, 1976-78\" \"Early Days - Irish Shows, 1976-78\" \"Early Days - Irish Shows, 1976-78\" \"Early Days - Irish Shows, 1976-78\" ...\n $ date         : Date[1:39674], format: \"1977-04-11\" \"1977-04-11\" ...\n $ venue        : chr [1:39674] \"St Fintan's School\" \"St Fintan's School\" \"St Fintan's School\" \"St Fintan's School\" ...\n $ city         : chr [1:39674] \"Dublin\" \"Dublin\" \"Dublin\" \"Dublin\" ...\n $ state        : chr [1:39674] NA NA NA NA ...\n $ country      : chr [1:39674] \"Ireland\" \"Ireland\" \"Ireland\" \"Ireland\" ...\n $ song_position: num [1:39674] 1 2 3 4 5 6 7 8 1 2 ...\n $ snippet      : logi [1:39674] FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ encore       : logi [1:39674] FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ song_title   : chr [1:39674] \"Show Me The Way\" \"Johnny B. Goode\" \"Nights In White Satin\" \"Peaceful Easy Feeling\" ...\n $ show_url     : chr [1:39674] \"https://www.u2gigs.com/show1.html\" \"https://www.u2gigs.com/show1.html\" \"https://www.u2gigs.com/show1.html\" \"https://www.u2gigs.com/show1.html\" ...\n $ song_url     : chr [1:39674] \"https://www.u2gigs.com/Show_Me_The_Way-s296.html\" \"https://www.u2gigs.com/Johnny_B_Goode-s561.html\" \"https://www.u2gigs.com/Nights_In_White_Satin-s562.html\" \"https://www.u2gigs.com/Peaceful_Easy_Feeling-s563.html\" ...\n $ song_lyrics  : chr [1:39674] \"I wonder how your feeling. There's ringing in my ears. And no one to relate to, 'cept the sea.  Who can I beliv\"| __truncated__ \"Deep down Louisiana close to New Orleans Way back up in the woods among the evergreens There stood a log cabin \"| __truncated__ \"Nights in white satin Never reaching the end; Letters I've written Never meaning to send  Beauty I'd always mis\"| __truncated__ \"I like the way your sparkling earrings lay, against your skin, it's so brown and I wanna sleep with you in the \"| __truncated__ ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   showID = col_double(),\n  ..   tour = col_character(),\n  ..   leg = col_character(),\n  ..   date = col_date(format = \"\"),\n  ..   venue = col_character(),\n  ..   city = col_character(),\n  ..   state = col_character(),\n  ..   country = col_character(),\n  ..   song_position = col_double(),\n  ..   snippet = col_logical(),\n  ..   encore = col_logical(),\n  ..   song_title = col_character(),\n  ..   show_url = col_character(),\n  ..   song_url = col_character(),\n  ..   song_lyrics = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt;",
    "crumbs": [
      "Home",
      "Getting the Data",
      "4. Initial Data Exploration"
    ]
  },
  {
    "objectID": "basic-stats-u2-concerts.html",
    "href": "basic-stats-u2-concerts.html",
    "title": "Basic Statistics U2 Concerts",
    "section": "",
    "text": "In this section we look at some basic statistics of the U2 shows and compare this with the statistics listed at https://www.u2gigs.com.",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "5. Basic Statistics U2 Concerts"
    ]
  },
  {
    "objectID": "basic-stats-u2-concerts.html#load-custom-concertdata-package",
    "href": "basic-stats-u2-concerts.html#load-custom-concertdata-package",
    "title": "Basic Statistics U2 Concerts",
    "section": "Load custom concertData package",
    "text": "Load custom concertData package\nFirst we load my custom concertData package where I organized all the functions to analyze the U2 concert data. This R package is available on my GitHub page at: https://github.com/vanleeuwen-hans/concertData.\n\nlibrary(devtools)\ndevtools::install_github(\"vanleeuwen-hans/concertData\")\nlibrary(concertData)\n\n\n# read the following file where the Rosemont duplication was not fixed yet\n# this is explained further down on this report\nu2data &lt;- read_concertData_csv('u2data/archive/u2data_all_shows_clean_final_rosemontdup.csv')",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "5. Basic Statistics U2 Concerts"
    ]
  },
  {
    "objectID": "basic-stats-u2-concerts.html#longest-set-lists",
    "href": "basic-stats-u2-concerts.html#longest-set-lists",
    "title": "Basic Statistics U2 Concerts",
    "section": "Longest set lists",
    "text": "Longest set lists\nList the shows with the longest set lists, i.e.¬†where U2 played most songs in a concert. The list corresponds to the statistics at https://www.u2gigs.com/tourdb-stats.html.\n\n# longest set lists\nlongest_setlists &lt;- find_longest_setlists(u2data)\nprint(longest_setlists)\n\n        date    city country             venue Number of songs played\n1 2015-12-06   Paris  France AccorHotels Arena                     27\n2 2018-05-02   Tulsa     USA        BOK Center                     27\n3 2015-10-18 Cologne Germany     Lanxess Arena                     27\n\n\nThe info at https://www.u2gigs.com/tourdb-stats.html:\n\n\n\nLongest U2 set lists - source u2gigs.com - October 2024.\n\n\nOne of these shows, with 27 songs played, was in Cologne on October 18th, 2015. I was there with my wife, and before the show we had the chance to meet and greet with Adam Clayton, U2‚Äôs bass player. He signed my copy of the 1991 Achtung Baby album. I have included some pictures of that moment below.",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "5. Basic Statistics U2 Concerts"
    ]
  },
  {
    "objectID": "basic-stats-u2-concerts.html#shows-with-most-snippets",
    "href": "basic-stats-u2-concerts.html#shows-with-most-snippets",
    "title": "Basic Statistics U2 Concerts",
    "section": "Shows with most snippets",
    "text": "Shows with most snippets\nA snippet is a short piece of song (either from another artist or from U2 themselves) played as part of a regular song in the show.\n\n# Get shows with most snippets\nsnippet_summary &lt;- find_shows_with_most_snippets(u2data)\nhead(snippet_summary, n=10)  # Show top 10 shows\n\n# A tibble: 10 √ó 5\n   date       city     country          venue             number_snippets_played\n   &lt;date&gt;     &lt;chr&gt;    &lt;chr&gt;            &lt;chr&gt;                              &lt;int&gt;\n 1 2015-11-28 Dublin   Ireland          3Arena                                24\n 2 2015-11-19 Belfast  Northern Ireland The SSE Arena                         23\n 3 2015-10-30 London   England          The O2                                23\n 4 2015-11-24 Dublin   Ireland          3Arena                                20\n 5 2015-11-23 Dublin   Ireland          3Arena                                20\n 6 2015-11-03 London   England          The O2                                20\n 7 2015-05-19 San Jose USA              SAP Center at Sa‚Ä¶                     20\n 8 2015-12-06 Paris    France           AccorHotels Arena                     19\n 9 2015-11-27 Dublin   Ireland          3Arena                                19\n10 1997-07-31 Mannheim Germany          Maimarkt                              19\n\n\nThe info at https://www.u2gigs.com/tourdb-stats.html:\n\n\n\nU2 shows with most snippets played - source u2gigs.com - October 2024.\n\n\nI noticed a discrepancy in number of snippets for some of these shows when comparing with the statistics at https://www.u2gigs.com/tourdb-stats.html, for example the London show on November 3rd, 2015, where my data calculates the number of snippets played as 20, while the info at https://www.u2gigs.com/show1957.html states 19. I first checked in my data which song was incorrectly identified as snippet. That turned out to be ‚ÄòEven Better Than The Real Thing‚Äô.\n\n# check london show 2015-11-03\nlondon_show &lt;- subset(u2data, date == '2015-11-03' & snippet == TRUE, select = c(\"showID\", \"date\",\"song_title\", \"snippet\"))\nprint(london_show, n = max())\n\n# A tibble: 20 √ó 4\n   showID date       song_title                           snippet\n    &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;                                &lt;lgl&gt;  \n 1   1957 2015-11-03 Van Morrison's Gloria                TRUE   \n 2   1957 2015-11-03 Do You Remember Rock 'n' Roll Radio? TRUE   \n 3   1957 2015-11-03 Hold Me Close                        TRUE   \n 4   1957 2015-11-03 When Johnny Comes Marching Home      TRUE   \n 5   1957 2015-11-03 Psalm 23                             TRUE   \n 6   1957 2015-11-03 Love and Peace or Else               TRUE   \n 7   1957 2015-11-03 Words                                TRUE   \n 8   1957 2015-11-03 A Clockwork Orange                   TRUE   \n 9   1957 2015-11-03 Even Better Than The Real Thing      TRUE   \n10   1957 2015-11-03 Burning Down The House               TRUE   \n11   1957 2015-11-03 Young Americans                      TRUE   \n12   1957 2015-11-03 1969                                 TRUE   \n13   1957 2015-11-03 Love Me Do                           TRUE   \n14   1957 2015-11-03 Ode To Joy                           TRUE   \n15   1957 2015-11-03 19                                   TRUE   \n16   1957 2015-11-03 California (There Is No End To Love) TRUE   \n17   1957 2015-11-03 Yellow                               TRUE   \n18   1957 2015-11-03 Live Forever                         TRUE   \n19   1957 2015-11-03 Mother And Child Reunion             TRUE   \n20   1957 2015-11-03 40                                   TRUE   \n\n\nThe issue seems to be in the different HTML coding for one snippet on that page: \nIf we check the HTML code for the ‚ÄòFish Out of Water Mix‚Äô we see that it has a ‚Äòsnippet‚Äô tag:\n&lt;li&gt;&lt;a href=\"/Even_Better_Than_The_Real_Thing-s38.html\"&gt;Even Better Than The Real Thing&lt;/a&gt; &lt;em class=\"snippet\"&gt;Fish Out of Water Mix&lt;/em&gt;&lt;/li&gt;\nNow compare this to what the HTML looks like normally for snippets at u2gigs.com:\n&lt;li&gt;&lt;a href=\"/Mysterious_Ways-s26.html\"&gt;Mysterious Ways&lt;/a&gt; / &lt;a class=\"snippet\" href=\"/Burning_Down_The_House-s878.html\"&gt;Burning Down The House&lt;/a&gt; &lt;span class=\"snippet\"&gt;(snippet)&lt;/span&gt; / &lt;a class=\"snippet\" href=\"/Young_Americans-s30.html\"&gt;Young Americans&lt;/a&gt; &lt;span class=\"snippet\"&gt;(snippet)&lt;/span&gt;&lt;/li&gt;\nI‚Äôm not sure what u2gigs.com intended to do here, and whether this is a snippet or not. It does explain the different numbers seen earlier as my scraping code has counted songs preceding songs with those tags as snippet incorrectly.",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "5. Basic Statistics U2 Concerts"
    ]
  },
  {
    "objectID": "basic-stats-u2-concerts.html#cities-with-most-shows",
    "href": "basic-stats-u2-concerts.html#cities-with-most-shows",
    "title": "Basic Statistics U2 Concerts",
    "section": "Cities with most shows",
    "text": "Cities with most shows\nWe used this metric for data curation already, but here is the top 11 (instead of Top 10 so that Amsterdam is displayed üòÄ ) of cities where U2 played most often. This matches exactly the statistics listed at https://www.u2gigs.com/tourdb-stats.html.\n\n# cities with most shows played\ntop_cities &lt;- find_most_played_cities(u2data, n = 13)\nprint(top_cities)\n\n              city number_of_shows\n1           Dublin             202\n2         New York             146\n3           London             126\n4        Las Vegas              54\n5      Los Angeles              53\n6          Chicago              41\n7           Boston              35\n8          Toronto              30\n9            Paris              29\n10 East Rutherford              27\n11          Sydney              27\n12      Washington              27\n13       Amsterdam              23\n\n\nThe info at https://www.u2gigs.com/tourdb-stats.html:\n\n\n\nCities with most shows played - source u2gigs.com - October 2024.",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "5. Basic Statistics U2 Concerts"
    ]
  },
  {
    "objectID": "basic-stats-u2-concerts.html#venues-with-most-shows",
    "href": "basic-stats-u2-concerts.html#venues-with-most-shows",
    "title": "Basic Statistics U2 Concerts",
    "section": "Venues with most shows",
    "text": "Venues with most shows\nHere is the top 10 of venues where U2 played most often. This matches exactly the statistics listed at https://www.u2gigs.com/tourdb-stats.html.\n\n# Get top 10 venues with most shows played\ntop_venues &lt;- find_most_played_venues(u2data, n = 10)\nprint(top_venues)\n\n                   venue        city number_of_shows\n1                 Sphere   Las Vegas              40\n2  Madison Square Garden    New York              30\n3            McGonagle's      Dublin              28\n4          United Center     Chicago              19\n5   Entertainment Centre      Sydney              14\n6             Croke Park      Dublin              13\n7           Sports Arena Los Angeles              13\n8         Staples Center Los Angeles              13\n9         Beacon Theatre    New York              13\n10      Arcadia Ballroom        Cork              11\n\n\nThe info at https://www.u2gigs.com/tourdb-stats.html:\n\n\n\nVenues with most shows played - source u2gigs.com - October 2024.",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "5. Basic Statistics U2 Concerts"
    ]
  },
  {
    "objectID": "basic-stats-u2-concerts.html#countries-with-most-shows",
    "href": "basic-stats-u2-concerts.html#countries-with-most-shows",
    "title": "Basic Statistics U2 Concerts",
    "section": "Countries with most shows",
    "text": "Countries with most shows\nThe top 10 of countries where U2 played most often can be seen below. This matches exactly the statistics listed at https://www.u2gigs.com/tourdb-stats.html.\n\n# countries with most shows played\n# Get top 10 countries with most shows played\ntop_countries &lt;- find_most_played_countries(u2data, n = 10)\nprint(top_countries)\n\n       country number_of_shows\n1          USA             930\n2      England             279\n3      Ireland             279\n4       Canada              80\n5      Germany              78\n6    Australia              75\n7       France              63\n8  Netherlands              61\n9        Italy              46\n10    Scotland              32\n\n\nThe info at https://www.u2gigs.com/tourdb-stats.html:\n\n\n\nCountries with most shows played - source u2gigs.com - October 2024.",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "5. Basic Statistics U2 Concerts"
    ]
  },
  {
    "objectID": "basic-stats-u2-concerts.html#top-10-most-played-songs",
    "href": "basic-stats-u2-concerts.html#top-10-most-played-songs",
    "title": "Basic Statistics U2 Concerts",
    "section": "Top 10 most played songs",
    "text": "Top 10 most played songs\nBefore we look at the top 10, let‚Äôs see how many different songs U2 has played live.\n\n# number of unique songs  played\nnrow(unique(u2data[,c('song_title')]))\n\n[1] 994\n\n\nThis does not match the info at https://www.u2gigs.com/all-songnames.html as there it is stated:\n\nWe have 1011 different songs in our database.\n\nHowever, at at a different page (https://www.u2gigs.com/most-played-songs.html) it is stated:\n\nWe found 994 different songs in our database.\n\nAnd that number coincides with the number found in my data.\nThe top 10 of songs that U2 played most often can be seen below. This does not match completely with the statistics listed at https://www.u2gigs.com/most-played-songs.html. There are several songs that have a count that is 1 higher in my data (Pride, Streets, One, Bullet, Still Haven‚Äôt Found).\n\n# songs most played\ntop_played_songs &lt;- find_most_played_songs(u2data, n = 15)\nprint(top_played_songs)\n\n# A tibble: 15 √ó 4\n   song_title       times_played_total times_played_regular times_played_snippet\n   &lt;chr&gt;                         &lt;int&gt;                &lt;int&gt;                &lt;int&gt;\n 1 Sunday Bloody S‚Ä¶               1082                  935                  147\n 2 Pride (In the N‚Ä¶               1057                 1057                    0\n 3 I Will Follow                  1053                 1053                    0\n 4 Where the Stree‚Ä¶                977                  975                    2\n 5 With or Without‚Ä¶                913                  910                    3\n 6 One                             865                  852                   13\n 7 New Year's Day                  805                  804                    1\n 8 Bullet the Blue‚Ä¶                793                  793                    0\n 9 I Still Haven't‚Ä¶                697                  691                    6\n10 Beautiful Day                   674                  673                    1\n11 Until the End o‚Ä¶                648                  648                    0\n12 Mysterious Ways                 639                  639                    0\n13 Vertigo                         603                  586                   17\n14 Bad                             568                  561                    7\n15 Elevation                       560                  558                    2\n\n\nThe info at https://www.u2gigs.com/tourdb-stats.html:\n\n\n\nMost played songs - source u2gigs.com - October 2024.\n\n\nI took a closer look at the song Pride to see where the difference of 1 time played is between my data and the data at https://www.u2gigs.com/Pride_(In_the_Name_of_Love)-s40.html. I copied all the times the song was played from that page and pasted in Excel. With the code below I obtained the list from my data and compared that side by side in Excel.\n\n# Pride - number of times played\npride_data &lt;- subset(u2data, song_title == 'Pride (In the Name of Love)', select = c(\"date\",\"city\",\"tour\", \"song_title\", \"showID\"))\n#write.csv(pride_data, \"pride_data.csv\")\n\nI discovered that the issue in my data is at the ZOO TV show on March 31, 1992 in Rosemont: https://www.u2gigs.com/show235.html. Pride was played one time at that show but appears in my data as it was played 2 times during that show:\n\n# Rosemont show 1992 set list\nrosemont_data &lt;- subset(u2data, showID == 235, select = c(\"date\", \"city\", \"song_position\",\"song_title\",\"snippet\", \"encore\"))\nprint(rosemont_data)\n\n# A tibble: 46 √ó 6\n   date       city     song_position song_title                   snippet encore\n   &lt;date&gt;     &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;                        &lt;lgl&gt;   &lt;lgl&gt; \n 1 1992-03-31 Rosemont             1 Zoo Station                  FALSE   FALSE \n 2 1992-03-31 Rosemont             2 The Fly                      FALSE   FALSE \n 3 1992-03-31 Rosemont             3 Even Better Than The Real T‚Ä¶ FALSE   FALSE \n 4 1992-03-31 Rosemont             4 Mysterious Ways              FALSE   FALSE \n 5 1992-03-31 Rosemont             4 Love To Love You Baby        TRUE    FALSE \n 6 1992-03-31 Rosemont             5 One                          FALSE   FALSE \n 7 1992-03-31 Rosemont             6 Until the End of the World   FALSE   FALSE \n 8 1992-03-31 Rosemont             7 Who's Gonna Ride Your Wild ‚Ä¶ FALSE   FALSE \n 9 1992-03-31 Rosemont             8 Tryin' to Throw Your Arms A‚Ä¶ FALSE   FALSE \n10 1992-03-31 Rosemont             8 Love And Affection           TRUE    FALSE \n# ‚Ñπ 36 more rows\n\n\nWith this we can see that there is duplicated data for this show in my data. I went back to my original scraped files and indeed I saw that the duplication happened where the scraping process had been interrupted and later restarted manually. Let‚Äôs check to what extent there are duplicated rows in my data:\n\n# show duplicate rows \nduplicated_rows &lt;- u2data[duplicated(u2data), ]\nprint(duplicated_rows, n=max())\n\n# A tibble: 24 √ó 15\n   showID tour  leg   date       venue city  state country song_position snippet\n    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;lgl&gt;  \n 1    235 U2 Z‚Ä¶ ZOO ‚Ä¶ 1992-03-31 Rose‚Ä¶ Rose‚Ä¶ Illi‚Ä¶ USA                 1 FALSE  \n 2    235 U2 Z‚Ä¶ ZOO ‚Ä¶ 1992-03-31 Rose‚Ä¶ Rose‚Ä¶ Illi‚Ä¶ USA                 2 FALSE  \n 3    235 U2 Z‚Ä¶ ZOO ‚Ä¶ 1992-03-31 Rose‚Ä¶ Rose‚Ä¶ Illi‚Ä¶ USA                 3 FALSE  \n 4    235 U2 Z‚Ä¶ ZOO ‚Ä¶ 1992-03-31 Rose‚Ä¶ Rose‚Ä¶ Illi‚Ä¶ USA                 4 FALSE  \n 5    235 U2 Z‚Ä¶ ZOO ‚Ä¶ 1992-03-31 Rose‚Ä¶ Rose‚Ä¶ Illi‚Ä¶ USA                 4 TRUE   \n 6    235 U2 Z‚Ä¶ ZOO ‚Ä¶ 1992-03-31 Rose‚Ä¶ Rose‚Ä¶ Illi‚Ä¶ USA                 5 FALSE  \n 7    235 U2 Z‚Ä¶ ZOO ‚Ä¶ 1992-03-31 Rose‚Ä¶ Rose‚Ä¶ Illi‚Ä¶ USA                 6 FALSE  \n 8    235 U2 Z‚Ä¶ ZOO ‚Ä¶ 1992-03-31 Rose‚Ä¶ Rose‚Ä¶ Illi‚Ä¶ USA                 7 FALSE  \n 9    235 U2 Z‚Ä¶ ZOO ‚Ä¶ 1992-03-31 Rose‚Ä¶ Rose‚Ä¶ Illi‚Ä¶ USA                 8 FALSE  \n10    235 U2 Z‚Ä¶ ZOO ‚Ä¶ 1992-03-31 Rose‚Ä¶ Rose‚Ä¶ Illi‚Ä¶ USA                 8 TRUE   \n# ‚Ñπ 14 more rows\n# ‚Ñπ 5 more variables: encore &lt;lgl&gt;, song_title &lt;chr&gt;, show_url &lt;chr&gt;,\n#   song_url &lt;chr&gt;, song_lyrics &lt;chr&gt;\n\n\nHere we see the Rosemont show (show ID 235) again. I manually checked the others:\n\nEl Pueblo Vencer√° at show with showID 1056, and also at show with showID 1060\n\nthis turned out to be correct as the snippet was played two times in the same regular song (Mothers of the Disappeared), so it looks like a duplicate row but is correct.\n\nTwo Shots of Happy, One Shot of Sad at show with showID 1133\n\nthis also turned out to be correct as the snippet was played two times in the same regular song (Stay), so it looks like a duplicate row but is correct.\n\n\nThis means I only have to remove the Rosemont show duplicate rows, as follows:\n\n# retrieve row indices of all duplicated rows \nwhich(duplicated(u2data) | duplicated(u2data, fromLast = TRUE))\n\n [1]  2959  2960  2961  2962  2963  2964  2965  2966  2967  2968  2969  2970\n[13]  2971  2972  2973  2974  2975  2976  2977  2978  2979  2980  2981  2982\n[25]  2983  2984  2985  2986  2987  2988  2989  2990  2991  2992  2993  2994\n[37]  2995  2996  2997  2998  2999  3000 18166 18168 18239 18241 20327 20329\n\n# the first 21 are the ones that should be deleted\n\n# check rows 20, 21 and 22 with indices 2959, 2979 and 2980, respectively\nu2data[2959,]\n\n# A tibble: 1 √ó 15\n  showID tour   leg   date       venue city  state country song_position snippet\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;date&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;lgl&gt;  \n1    235 U2 ZO‚Ä¶ ZOO ‚Ä¶ 1992-03-31 Rose‚Ä¶ Rose‚Ä¶ Illi‚Ä¶ USA                 1 FALSE  \n# ‚Ñπ 5 more variables: encore &lt;lgl&gt;, song_title &lt;chr&gt;, show_url &lt;chr&gt;,\n#   song_url &lt;chr&gt;, song_lyrics &lt;chr&gt;\n\nu2data[2979,]\n\n# A tibble: 1 √ó 15\n  showID tour   leg   date       venue city  state country song_position snippet\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;date&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;lgl&gt;  \n1    235 U2 ZO‚Ä¶ ZOO ‚Ä¶ 1992-03-31 Rose‚Ä¶ Rose‚Ä¶ Illi‚Ä¶ USA                17 FALSE  \n# ‚Ñπ 5 more variables: encore &lt;lgl&gt;, song_title &lt;chr&gt;, show_url &lt;chr&gt;,\n#   song_url &lt;chr&gt;, song_lyrics &lt;chr&gt;\n\nu2data[2980,]\n\n# A tibble: 1 √ó 15\n  showID tour   leg   date       venue city  state country song_position snippet\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;date&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;lgl&gt;  \n1    235 U2 ZO‚Ä¶ ZOO ‚Ä¶ 1992-03-31 Rose‚Ä¶ Rose‚Ä¶ Illi‚Ä¶ USA                 1 FALSE  \n# ‚Ñπ 5 more variables: encore &lt;lgl&gt;, song_title &lt;chr&gt;, show_url &lt;chr&gt;,\n#   song_url &lt;chr&gt;, song_lyrics &lt;chr&gt;\n\n# correct, these two rows correspond to the first one to delete (Zoo Station), the last one to delete (Desire) and the first one to keep (Zoo Station), respectively\n\n# thus, we need to remove the rows with indices:\n# 2959  2960  2961  2962  2963  2964  2965  2966  2967  2968  2969  2970  2971  2972  2973  2974  2975\n# 2976  2977  2978  2979\n\n# check number of rows before deletion\nnrow(u2data)\n\n[1] 39674\n\n# result: 39674\n\n# delete duplicated rows from Rosemont show\nu2data &lt;- u2data[-(2959:2979),]\n\n# check number of rows after deletion\nnrow(u2data)\n\n[1] 39653\n\n#result: 39653\n\n# difference: 39674 - 39653\nprint(39674 - 39653)\n\n[1] 21\n\n# result: 21\n#correct\n\n# now save corrected data to csv file\n# commented out because this has already been done\n#write.csv(u2data, file = \"u2data/u2data_all_shows_clean_final.csv\", row.names = FALSE)\n\nNow that those duplicated rows were removed, let‚Äôs look at the songs by number of times played again and compare again to the info at https://www.u2gigs.com/most-played-songs.html.\n\n# read the u2 concertData\nu2data &lt;- read_concertData_csv('u2data/u2data_all_shows_clean_final.csv')\n\n# songs most played\ntop_played_songs &lt;- find_most_played_songs(u2data, n = 15)\nprint(top_played_songs)\n\n# A tibble: 15 √ó 4\n   song_title       times_played_total times_played_regular times_played_snippet\n   &lt;chr&gt;                         &lt;int&gt;                &lt;int&gt;                &lt;int&gt;\n 1 Sunday Bloody S‚Ä¶               1082                  935                  147\n 2 Pride (In the N‚Ä¶               1056                 1056                    0\n 3 I Will Follow                  1053                 1053                    0\n 4 Where the Stree‚Ä¶                976                  974                    2\n 5 With or Without‚Ä¶                913                  910                    3\n 6 One                             864                  851                   13\n 7 New Year's Day                  805                  804                    1\n 8 Bullet the Blue‚Ä¶                792                  792                    0\n 9 I Still Haven't‚Ä¶                696                  690                    6\n10 Beautiful Day                   674                  673                    1\n11 Until the End o‚Ä¶                647                  647                    0\n12 Mysterious Ways                 638                  638                    0\n13 Vertigo                         603                  586                   17\n14 Bad                             567                  560                    7\n15 Elevation                       560                  558                    2\n\n\nYes, total times the songs were played match now. There is still discrepancies in the times it was played as regular song or snippet.\n\n\n\nTop played songs - u2gigs.com - October 2024.\n\n\nLet‚Äôs check Where The Streets Have No Name. In the u2gigs.com it has a total play count of 976, all regular performances, no snippets. In my data it states 974 regular performances and 2 times as a snippet.\n\nWTSHNN_regular_play_count &lt;- subset(u2data, song_title == 'Where the Streets Have No Name' & snippet == FALSE, select = c(\"showID\", \"date\", \"city\", \"song_position\",\"song_title\",\"snippet\", \"encore\"))\nprint(WTSHNN_regular_play_count)\n\n# A tibble: 974 √ó 7\n   showID date       city           song_position song_title      snippet encore\n    &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;                  &lt;dbl&gt; &lt;chr&gt;           &lt;lgl&gt;   &lt;lgl&gt; \n 1      8 1990-01-05 Rotterdam                  5 Where the Stre‚Ä¶ FALSE   FALSE \n 2      9 1990-01-06 Rotterdam                  1 Where the Stre‚Ä¶ FALSE   FALSE \n 3     11 1990-01-09 Rotterdam                  1 Where the Stre‚Ä¶ FALSE   FALSE \n 4     12 1990-01-10 Rotterdam                  6 Where the Stre‚Ä¶ FALSE   FALSE \n 5     29 1998-01-27 Rio de Janeiro            16 Where the Stre‚Ä¶ FALSE   FALSE \n 6     37 1998-01-30 Sao Paulo                 15 Where the Stre‚Ä¶ FALSE   FALSE \n 7     42 1998-01-31 Sao Paulo                 15 Where the Stre‚Ä¶ FALSE   FALSE \n 8     55 1998-02-05 Buenos Aires              15 Where the Stre‚Ä¶ FALSE   FALSE \n 9     58 1998-02-06 Buenos Aires              15 Where the Stre‚Ä¶ FALSE   FALSE \n10     59 1998-02-07 Buenos Aires              16 Where the Stre‚Ä¶ FALSE   FALSE \n# ‚Ñπ 964 more rows\n\nWTSHNN_snippet_play_count &lt;- subset(u2data, song_title == 'Where the Streets Have No Name' & snippet == TRUE, select = c(\"showID\", \"date\", \"city\", \"song_position\",\"song_title\",\"snippet\", \"encore\"))\nprint(WTSHNN_snippet_play_count)\n\n# A tibble: 2 √ó 7\n  showID date       city     song_position song_title             snippet encore\n   &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;                  &lt;lgl&gt;   &lt;lgl&gt; \n1   1887 2014-12-01 New York             4 Where the Streets Hav‚Ä¶ TRUE    TRUE  \n2   2108 2017-12-04 New York             4 Where the Streets Hav‚Ä¶ TRUE    FALSE \n\n\nIn the two shows where my scraping code had counted WTSHNN as a snippet, we see the format difference:\n&lt;li&gt;&lt;a href='/Where_the_Streets_Have_No_Name-s17.html'&gt;Where the Streets Have No Name&lt;/a&gt; &lt;span class='guestartist'&gt;(with Bruce Springsteen)&lt;/span&gt;&lt;/li&gt;\n\n&lt;li&gt;&lt;a href='/Where_the_Streets_Have_No_Name-s17.html'&gt;Where the Streets Have No Name&lt;/a&gt; &lt;em class='snippet'&gt;partial chords&lt;/em&gt;&lt;/li&gt;\nCompared to a more normal coding for regular songs on the u2gigs.com site:\n&lt;li&gt;&lt;a href='/Where_the_Streets_Have_No_Name-s17.html'&gt;Where the Streets Have No Name&lt;/a&gt;&lt;/li&gt;\nThus, my scraping code had not identified these two performances of WTSHNN as regular but incorrectly as snippets. As my project was ending I did not follow up to correct my u2data set with these relativelz few errors in the snippet flag.",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "5. Basic Statistics U2 Concerts"
    ]
  },
  {
    "objectID": "basic-stats-u2-concerts.html#top-10-opening-songs",
    "href": "basic-stats-u2-concerts.html#top-10-opening-songs",
    "title": "Basic Statistics U2 Concerts",
    "section": "Top 10 opening songs",
    "text": "Top 10 opening songs\nWhich were the songs U2 played most to open the shows? This can be seen at https://www.u2gigs.com/tourdb-stats.html.\n\n\n\nTop 10 opening songs - u2gigs.com - October 2024.\n\n\nIn my data the numbers are like shown below:\n\n# Get top 10 opening songs\ntop_10_openers &lt;- find_most_played_opening_songs(u2data, n = 10)\nprint(top_10_openers)\n\n# A tibble: 10 √ó 2\n   song_title                     times_played\n   &lt;chr&gt;                                 &lt;int&gt;\n 1 Zoo Station                             197\n 2 Gloria                                  130\n 3 Elevation                               118\n 4 11 O'Clock Tick Tock                    117\n 5 City of Blinding Lights                 116\n 6 Where the Streets Have No Name          114\n 7 Mofo                                     94\n 8 The Miracle (of Joey Ramone)             85\n 9 Out of Control                           72\n10 Sunday Bloody Sunday                     71\n\n\nThe numbers did not match the information at https://www.u2gigs.com/tourdb-stats.html. I checked a few songs and observed a few things:\nFirst, the opening songs counts listed at https://www.u2gigs.com/tourdb-stats.html seem to be outdated. When you click on one the songs in that list it shows a different number on the song page. For example, Zoo Station has the opening song count of 196 at https://www.u2gigs.com/tourdb-stats.html (see earlier screen shot), but 197 at https://www.u2gigs.com/openingsong141.html:\n\n\n\nZoo Station opening song - u2gigs.com - October 2024.\n\n\nThus, it looks like u2gigs.com needs to refresh the ‚ÄòTop 25 show opening songs‚Äô list at https://www.u2gigs.com/tourdb-stats.html.\nSecond, I observed a few rare cases on the u2gigs.com show pages which were not handled properly by my scraping code, or were not handled properly by u2gigs.com, for example:\nExample 1:\nOct 23rd, 2000 set list, https://www.u2gigs.com/show1147.html: \nMy code and data did count Elevation as opening song for this ‚Äòshow‚Äô while u2gigs.com did not count it, probably because it was preceded by an interview.\nThe same issue occurred with this show: https://www.u2gigs.com/show1149.html, and potentially with other shows as I only checked shows that opened with Elevation. u2gigs.com may want to check how they count opening songs in such case.\nExample 2\n2001-09-06 set list, https://www.u2gigs.com/show1473.html. In this case the set list started with a medley, with two songs as one entry. This is different than a regular song plus a snippet. My scraping code could apparently not handle this.\n\n\n\nRare setlist format on show page.\n\n\nI decided not to invest more time in trying to detect and fix these rare issues.",
    "crumbs": [
      "Home",
      "Analysis & Visualization",
      "5. Basic Statistics U2 Concerts"
    ]
  },
  {
    "objectID": "prepare-the-data.html",
    "href": "prepare-the-data.html",
    "title": "Data Preparation",
    "section": "",
    "text": "In the online U2 community there is an excellent resource that has detailed information of all the concerts U2 ever played live, starting in their kitchen and high school in the late seventies in Dublin, Ireland, and evolving into world-wide tours with packed stadiums. This resource is u2gigs.com, created and maintained by Matthias M√ºhlbradt and Andr√© Axver. For my Capstone Project of the Google Data Analytics certification I asked for permission to use the data and this was kindly granted by Matt. Thank you very much!\nMatt kindly offered to provide me with a database dump, but I decided to practice my coding skills and developed a web scraping approach that collected the data from the u2gigs.com site. The code for the web scraping is not shared here in my GitHub repository to avoid potential misuse of the code. I do explain the approach with a high-level outline of the methodology.",
    "crumbs": [
      "Home",
      "Getting the Data",
      "2. Data Preparation"
    ]
  },
  {
    "objectID": "prepare-the-data.html#source-of-the-data",
    "href": "prepare-the-data.html#source-of-the-data",
    "title": "Data Preparation",
    "section": "",
    "text": "In the online U2 community there is an excellent resource that has detailed information of all the concerts U2 ever played live, starting in their kitchen and high school in the late seventies in Dublin, Ireland, and evolving into world-wide tours with packed stadiums. This resource is u2gigs.com, created and maintained by Matthias M√ºhlbradt and Andr√© Axver. For my Capstone Project of the Google Data Analytics certification I asked for permission to use the data and this was kindly granted by Matt. Thank you very much!\nMatt kindly offered to provide me with a database dump, but I decided to practice my coding skills and developed a web scraping approach that collected the data from the u2gigs.com site. The code for the web scraping is not shared here in my GitHub repository to avoid potential misuse of the code. I do explain the approach with a high-level outline of the methodology.",
    "crumbs": [
      "Home",
      "Getting the Data",
      "2. Data Preparation"
    ]
  },
  {
    "objectID": "prepare-the-data.html#data-structure",
    "href": "prepare-the-data.html#data-structure",
    "title": "Data Preparation",
    "section": "Data structure",
    "text": "Data structure\nTo answer the questions I had asked myself at the beginning of this project, I decided that I needed to collect the following data fields from u2gigs.com:\n\nshowID: the ID for this show as used on u2gigs.com\ntour: the name of the U2 tour the show was part of (e.g.¬†U2 ZOO TV Tour)\nleg: the name of the tour leg the show was part of (e.g.¬†ZOO TV 1st leg: North America)\ndate: the date when the show took place\nvenue: the name of the stadium, arena, pub, school or other type of venue where the concert took place (e.g Madison Square Garden)\ncity: the city where the show took place (e.g New York)\nstate: the state where the show took place (e.g New York)\ncountry: the country where the show took place (e.g USA)\nsong_position: the position in the show set list when this song was played (e.g.¬†1 for the opening song)\nsnippet: a boolean indicating if this was a regular song, or if it was just a song snippet inserted before or after a regular song (e.g.¬†TRUE or FALSE)\nencore: a boolean indicating if this song was played in the main set list or in the encore, after the band took a short break (e.g.¬†TRUE or FALSE)\nsong_title: the title of the song (e.g.¬†Sunday Bloody Sunday)\nshow_url: the URL to the show info on u2gigs.com\nsong_url: the URL to the song info on u2gigs.com\nsong_lyrics: the lyrics of the song (e.g.¬†‚ÄòI can‚Äôt believe the news today, I can‚Äôt close my eyes and make it go away‚Ä¶..‚Äô)\n\nFor this project I decided to work with one aggregated data files containing all this information. From a data management perspective, it would be wiser to structure the data into different levels, and then these different levels would be linked to each other, like in a relational database with primary and foreign keys. I posed a question to Claude.AI to come up with a possible database scheme, and it provided the following possible Entity Relationship Diagram in mere seconds:\n\n\n\nu2data Entity Relationship Diagram created by Claude.AI",
    "crumbs": [
      "Home",
      "Getting the Data",
      "2. Data Preparation"
    ]
  },
  {
    "objectID": "prepare-the-data.html#web-scraping-methodology",
    "href": "prepare-the-data.html#web-scraping-methodology",
    "title": "Data Preparation",
    "section": "Web scraping methodology",
    "text": "Web scraping methodology\nOn u2gigs.com each show has a web page, and each song ever played has a web page. The earliest show available is from 1976 when U2 played at their Mount Temple Comprehensive School in Dublin. The last show available at the time of this project was in the Sphere in Las Vegas on March 2, 2024. The outline of the scraping approach can be seen below. For details feel free to reach out to me.\n\niterate over all the U2 show pages at u2gigs.com (starting with showID 1 all the way to showID 2307)\n\ncheck if page returns a result and skip to next one if needed\nretrieve the show meta data:\n\ntour\nleg\ndate\nvenue\ncity\nstate\ncountry\n\nretrieve and iterate over all list items from the html\n\ncheck if a song is present in this item\ncheck if this is a regular song or a snippet\ncheck if we are in the encore part of the show or not\nproperly deal with songs that are played more than once in this show\nstore song page URL for later\ncapture position of song in set list\n\nif there was no set list for this show\n\nstore show meta-data and fill NA for song related fields\nskip to next show\n\niterate over all detected songs\n\nconnect to the song page URL to retrieve song info:\n\nsong_title\nsong_lyrics\n\ndeal properly with song pages that do not contain lyrics\nremove line break HTML codes before storing the lyrics\nwrite all captured show and song data to file\n\nwait 10 seconds before connecting to the next show page to avoid overloading u2gigs.com with requests\n\ndisplay some stats:\n\nNumber of shows processed\nNumber of shows without setlist\nNumber of regular songs processed\nNumber of song snippets processed",
    "crumbs": [
      "Home",
      "Getting the Data",
      "2. Data Preparation"
    ]
  },
  {
    "objectID": "prepare-the-data.html#scraping-code-challenges-and-opportunities",
    "href": "prepare-the-data.html#scraping-code-challenges-and-opportunities",
    "title": "Data Preparation",
    "section": "Scraping code challenges and opportunities",
    "text": "Scraping code challenges and opportunities\n\nAfter having scraped all the required data I realized that my code was unnecessarily connecting multiple times to the song pages, every time it appeared in a show set list. It would have been better to store the song info in a separate data frame or file, so that the code would only connect to each song web page once.\nThe approach to iterate over list items for song detection, and checking the full page html content for encore detection (because the encore word was not inside list items) was cumbersome, especially if songs were played more than once in a show. I included some workarounds in the code but data verification needed to be done to check if there were perhaps shows where the encore flag was not properly set for songs. For example, during the Popmart Tour the encore usually started with the Lemon Perfecto Mix which was not linked to a song page. The different code caused an issue, but I wrote a workaround specifically for that.\nSnippet detection required quite some trial and error, because some songs have a snippet at the start, others at the end, some songs have only one snippet, others more than one. Eventually I could capture all of that that correctly.\nThe song_lyrics field resulted in many issues when loading the file into R. With hindsight, it would have been better to clean up that string before writing it to the data file.\nThe scraping of the u2gigs.com site (with permission) took several hours, and eventually I had to complete it in 3 runs of the code. However, this resulted in the final merged data file having some songs duplicated for one concert. I discovered this while analyzing most played songs, as described on the the Basic Statistics U2 Concerts page. With hindsight, I should have checked the 3 partial data files before merging these.\nThe ‚ÄòTop 25 show opening songs‚Äô listed at https://www.u2gigs.com/tourdb-stats.html seem to be outdated. More details in my project report on the Basic Statistics U2 Concerts page.\nAs described on the Basic Statistics U2 Concerts page in this report, there were some set lists where u2gigs.com did not count songs as opening songs if these were preceded by an interview (shows during promo tours). My code did count those as opening songs, hence some discrepancies in numbers.\nAlso described on the Basic Statistics U2 Concerts page is a rare example of a set list that started with a medley of two regular songs (not snippets). My scraping code did not handle such case(s) properly.",
    "crumbs": [
      "Home",
      "Getting the Data",
      "2. Data Preparation"
    ]
  },
  {
    "objectID": "process-clean-and-fix-the-data.html",
    "href": "process-clean-and-fix-the-data.html",
    "title": "Data Processing & Cleaning",
    "section": "",
    "text": "As the scraping was not completed in one time (it took several hours!), I executed three runs of the code, resulting in 3 data files. These data files were concatenated on the command line on MacOS using the following code.\n\nResulting files from scraping of u2gigs.com:\n\nu2analytics_data_shows1-234.csv\nu2analytics_data_shows235-298.csv\nu2analytics_data_shows299-2307.csv\n\nNow combine everything into one data file:\n\nFirst create new file with header:\n\nhead -n 1 u2analytics_data_shows1-234.csv &gt; u2data_all_shows.csv\n\nThen concatenate content from 3 data files into the new file (skipping headers):\n\ntail -n +2 -q u2analytics_data_shows*.csv &gt;&gt; u2data_all_shows.csv\n\n\nCheck number of lines in original 3 files and final data file:\nwc -l u2analytics_data_shows*\n\n2980 u2analytics_data_shows1-234.csv\n1176 u2analytics_data_shows235-298.csv\n35222 u2analytics_data_shows299-2307.csv\n39378 total\n\nwc -l u2data_all_shows.csv\n\n39376 u2data_all_shows.csv\n\nDifference is the header lines -&gt; correct",
    "crumbs": [
      "Home",
      "Getting the Data",
      "3. Data Processing & Cleaning"
    ]
  },
  {
    "objectID": "process-clean-and-fix-the-data.html#concatenating-the-scraped-data-files",
    "href": "process-clean-and-fix-the-data.html#concatenating-the-scraped-data-files",
    "title": "Data Processing & Cleaning",
    "section": "",
    "text": "As the scraping was not completed in one time (it took several hours!), I executed three runs of the code, resulting in 3 data files. These data files were concatenated on the command line on MacOS using the following code.\n\nResulting files from scraping of u2gigs.com:\n\nu2analytics_data_shows1-234.csv\nu2analytics_data_shows235-298.csv\nu2analytics_data_shows299-2307.csv\n\nNow combine everything into one data file:\n\nFirst create new file with header:\n\nhead -n 1 u2analytics_data_shows1-234.csv &gt; u2data_all_shows.csv\n\nThen concatenate content from 3 data files into the new file (skipping headers):\n\ntail -n +2 -q u2analytics_data_shows*.csv &gt;&gt; u2data_all_shows.csv\n\n\nCheck number of lines in original 3 files and final data file:\nwc -l u2analytics_data_shows*\n\n2980 u2analytics_data_shows1-234.csv\n1176 u2analytics_data_shows235-298.csv\n35222 u2analytics_data_shows299-2307.csv\n39378 total\n\nwc -l u2data_all_shows.csv\n\n39376 u2data_all_shows.csv\n\nDifference is the header lines -&gt; correct",
    "crumbs": [
      "Home",
      "Getting the Data",
      "3. Data Processing & Cleaning"
    ]
  },
  {
    "objectID": "process-clean-and-fix-the-data.html#importing-the-data-into-r-for-further-curation",
    "href": "process-clean-and-fix-the-data.html#importing-the-data-into-r-for-further-curation",
    "title": "Data Processing & Cleaning",
    "section": "Importing the data into R for further curation",
    "text": "Importing the data into R for further curation\nThe data curation was an iterative process of checking the data, identifying issues, fixing the issues followed by another round of curation. The R code chunk below shows the multiple iterations that were done, followed by paragraphs explaining the issues that were observed and fixed in these iterations.",
    "crumbs": [
      "Home",
      "Getting the Data",
      "3. Data Processing & Cleaning"
    ]
  },
  {
    "objectID": "process-clean-and-fix-the-data.html#fix-problems-in-song_lyrics-field",
    "href": "process-clean-and-fix-the-data.html#fix-problems-in-song_lyrics-field",
    "title": "Data Processing & Cleaning",
    "section": "Fix problems in song_lyrics field",
    "text": "Fix problems in song_lyrics field\nWhen reading the data file with read_csv() a problems attribute was created with 979 rows. There were many rows from the file that have an unexpected number of columns. I manually inspected a sample of these lines in the original data file.\nThen I checked three lines that give a problem with read_csv, focusing on the song_lyrics field:\nsed '2981!d' u2data_all_shows.csv \nsed '1150!d' u2data_all_shows.csv\nsed '115!d' u2data_all_shows.csv\nI found different issues in the song_lyrics field:\n\n‚Äú‚Äú;; at the end of the line instead of a single‚Äù\n‚Äù escaped quote characters in the song_lyrics field\n\nI used the following awk commands on MacOS to fix these two issues:\nawk '{gsub(/\\\\\"/,\"\")}1' u2data_all_shows.csv &gt; u2data_all_shows_fixquotes.csv\nawk '{gsub(/\";;/,\"\")}1' u2data_all_shows_fixquotes.csv &gt; u2data_all_shows_fixquotes-semicolons.csv",
    "crumbs": [
      "Home",
      "Getting the Data",
      "3. Data Processing & Cleaning"
    ]
  },
  {
    "objectID": "process-clean-and-fix-the-data.html#fix-invalid-date-issue",
    "href": "process-clean-and-fix-the-data.html#fix-invalid-date-issue",
    "title": "Data Processing & Cleaning",
    "section": "Fix invalid date issue",
    "text": "Fix invalid date issue\nIn the file 18 lines were found where an invalid date was present with 00 for the day. I used a MacOS command line to fix this on the data file:\ngrep '\\-00' u2data_all_shows_fixquotes-semicolons.csv |  wc -l\n      18\nawk '{gsub(/\\-00/,\"-01\")}1' u2data_all_shows_fixquotes-semicolons.csv &gt; u2data_all_shows_fixquotes-semicolons-dates.csv\ngrep '\\-00' u2data_all_shows_fixquotes-semicolons-dates.csv | wc -l                                     \n       0",
    "crumbs": [
      "Home",
      "Getting the Data",
      "3. Data Processing & Cleaning"
    ]
  },
  {
    "objectID": "process-clean-and-fix-the-data.html#fix-additional-issues-in-the-song_lyrics-field",
    "href": "process-clean-and-fix-the-data.html#fix-additional-issues-in-the-song_lyrics-field",
    "title": "Data Processing & Cleaning",
    "section": "Fix additional issues in the song_lyrics field",
    "text": "Fix additional issues in the song_lyrics field\nFile was read again with read_csv() and problems() showed that there were still 30 lines with a problem. Here the most likely culprits are again in the song_lyrics field.\n\nan extra ‚Äù at the end of the line\n\nFix the extra ‚Äù at the end of the line:\ngrep '\"\"\\r' u2data_all_shows_fixquotes-semicolons-dates.csv | wc -l\n      8\nawk '{gsub(/\"\"\\r/,\"\\\\\\\"\\r\")}1' u2data_all_shows_fixquotes-semicolons-dates.csv &gt; u2data_all_shows_fixquotes-semicolons-dates-others.csv\ngrep '\"\"\\r' u2data_all_shows_fixquotes-semicolons-dates-others.csv | wc -l\n       0\nLoading the file with read_csv() shows that now the file still has 23 problem lines. Inspecting some problem lines, I observed the following potential issues in the song_lyrics field:\n\n‚Äú;‚Äù\n‚Äú‚Äú; at the end of the line Fixed this in the following manner:\n\ngrep '\";\"' u2data_all_shows_fixquotes-semicolons-dates-others.csv | wc -l\n      22\ngrep '\"\";\\r' u2data_all_shows_fixquotes-semicolons-dates-others.csv | wc -l\n      22\n      \nawk '{gsub(/\";\"/,\"\")}1' u2data_all_shows_fixquotes-semicolons-dates-others.csv &gt; u2data_all_shows_fixquotes-semicolons-dates-others-2.csv\n\nawk '{gsub(/\"\";\\r/,\"\\\\\\\"\\r\")}1' u2data_all_shows_fixquotes-semicolons-dates-others-2.csv &gt; u2data_all_shows_fixquotes-semicolons-dates-others-3.csv\n\ngrep '\";\"' u2data_all_shows_fixquotes-semicolons-dates-others-3.csv | wc -l\n      0\ngrep '\"\";\\r' u2data_all_shows_fixquotes-semicolons-dates-others-3.csv | wc -l\n      0\nLoading the file with read_csv() shows that now the file still has 1 problem line. I observed that two lines were concatenated, meaning that the carriage return character was missing. Here is the part of the line that shows this:\nsed '4156!d' u2data_all_shows_fixquotes-semicolons-dates-others-3.csv\nw I will follow...  \"299,\"U2 Unforgettable Fire Tour\",\"T\nFixed this in the following manner:\ngrep '\"299,' u2data_all_shows_fixquotes-semicolons-dates-others-3.csv | wc -l\n      1\nawk '{gsub(/\"299,/,\"\\\"\\n299,\")}1' u2data_all_shows_fixquotes-semicolons-dates-others-3.csv &gt; u2data_all_shows_fixquotes-semicolons-dates-others-4.csv\n\ngrep '\"299,' u2data_all_shows_fixquotes-semicolons-dates-others-4.csv | wc -l\n      1\n      \nsed '4156!d' u2data_all_shows_fixquotes-semicolons-dates-others-4.csv  \nsed '4157!d' u2data_all_shows_fixquotes-semicolons-dates-others-4.csv",
    "crumbs": [
      "Home",
      "Getting the Data",
      "3. Data Processing & Cleaning"
    ]
  },
  {
    "objectID": "process-clean-and-fix-the-data.html#data-cleaning-result",
    "href": "process-clean-and-fix-the-data.html#data-cleaning-result",
    "title": "Data Processing & Cleaning",
    "section": "Data cleaning result",
    "text": "Data cleaning result\nReading the last fixed file with read_csv() gave 0 errors and the following info:\nRows: 39376 Columns: 15\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr  (10): tour, leg, venue, city, state, country, song_title, show_url, song_url, song_lyrics\ndbl   (2): showID, song_position\nlgl   (2): snippet, encore\ndate  (1): date\nI stored this fixed data file with a better file name:\ncp u2data_all_shows_fixquotes-semicolons-dates-others-4.csv u2data_all_shows_clean.csv",
    "crumbs": [
      "Home",
      "Getting the Data",
      "3. Data Processing & Cleaning"
    ]
  },
  {
    "objectID": "sharing.html",
    "href": "sharing.html",
    "title": "Sharing",
    "section": "",
    "text": "This project evolved over time, and more structure and organization of code, data and reports was needed. With some tips from Claude.AI I eventually arrived to the following set up, using a combination of public and private GitHub repositories for code, R-package, Quarto website and data management and version control, the R Studio local environment connected to GitHub and the shinyapps.io hosting platform for the interactive visualization apps. This Mermaid diagram gives the overall set-up:\n\n\n\n\n\nflowchart TB\n\n    %% Main Project Repository\n    MainRepo[\"u2_data_analytics\\n(GitHub Repository)\"]\n    MainBranch{{\"main branch\\n(Quarto docs & code)\"}}\n    GHPages{{\"gh-pages branch\\n(rendered website)\"}}\n    Website&gt;\"üìÉ Project Website\\nvanleeuwen-hans.github.io/\\nu2_data_analytics\"]\n\n    %% R Package\n    Package[\"concertData\\n(Public R Package)\\nüì¶ Available on GitHub\"]\n    PackageWeb&gt;\"Package Documentation\\nvanleeuwen-hans.github.io/\\nconcertData\"]\n\n    %% Private Data Repository\n    DataRepo[\"u2_data_analytics_data\\n(üîê Private GitHub Repository)\"]\n\n    %% Shiny Apps\n    ShinyRepo1[\"u2_tour_map\\n(GitHub Repository)\"]\n    ShinyApp1(\"üåé Tour Map Shiny App\\nqjxo03-hans-van0leeuwen.\\nshinyapps.io/u2_tour_map/\")\n    ShinyRepo2[\"u2_setlist_alignment\\n(GitHub Repository)\"]\n    ShinyApp2(\"üéº Setlist Alignment Shiny App\\nqjxo03-hans-van0leeuwen.\\nshinyapps.io/u2_setlist_alignment/\")\n\n    subgraph Support [\"Support Components\"]\n        direction TB\n        Package --&gt; PackageWeb\n        DataRepo\n    end\n    \n    subgraph Main [\"Main Project\"]\n        direction LR\n        MainRepo --&gt; MainBranch\n        MainRepo --&gt; GHPages\n        GHPages --&gt; Website\n    end\n\n    subgraph Apps [\"Shiny Applications\"]\n        direction LR\n        ShinyRepo1 --&gt; ShinyApp1\n        ShinyRepo2 --&gt; ShinyApp2\n    end\n\n    %% Connections between subgraphs\n    MainRepo -.-&gt; Package\n    DataRepo -.-&gt; MainRepo\n    Package -.-&gt; ShinyRepo1\n    Package -.-&gt; ShinyRepo2\n    Website -.-&gt; PackageWeb\n    Website -.-&gt; ShinyApp1\n    Website -.-&gt; ShinyApp2",
    "crumbs": [
      "Home",
      "Conclusions and Sharing",
      "10. Sharing"
    ]
  },
  {
    "objectID": "sharing.html#introduction",
    "href": "sharing.html#introduction",
    "title": "Sharing",
    "section": "",
    "text": "This project evolved over time, and more structure and organization of code, data and reports was needed. With some tips from Claude.AI I eventually arrived to the following set up, using a combination of public and private GitHub repositories for code, R-package, Quarto website and data management and version control, the R Studio local environment connected to GitHub and the shinyapps.io hosting platform for the interactive visualization apps. This Mermaid diagram gives the overall set-up:\n\n\n\n\n\nflowchart TB\n\n    %% Main Project Repository\n    MainRepo[\"u2_data_analytics\\n(GitHub Repository)\"]\n    MainBranch{{\"main branch\\n(Quarto docs & code)\"}}\n    GHPages{{\"gh-pages branch\\n(rendered website)\"}}\n    Website&gt;\"üìÉ Project Website\\nvanleeuwen-hans.github.io/\\nu2_data_analytics\"]\n\n    %% R Package\n    Package[\"concertData\\n(Public R Package)\\nüì¶ Available on GitHub\"]\n    PackageWeb&gt;\"Package Documentation\\nvanleeuwen-hans.github.io/\\nconcertData\"]\n\n    %% Private Data Repository\n    DataRepo[\"u2_data_analytics_data\\n(üîê Private GitHub Repository)\"]\n\n    %% Shiny Apps\n    ShinyRepo1[\"u2_tour_map\\n(GitHub Repository)\"]\n    ShinyApp1(\"üåé Tour Map Shiny App\\nqjxo03-hans-van0leeuwen.\\nshinyapps.io/u2_tour_map/\")\n    ShinyRepo2[\"u2_setlist_alignment\\n(GitHub Repository)\"]\n    ShinyApp2(\"üéº Setlist Alignment Shiny App\\nqjxo03-hans-van0leeuwen.\\nshinyapps.io/u2_setlist_alignment/\")\n\n    subgraph Support [\"Support Components\"]\n        direction TB\n        Package --&gt; PackageWeb\n        DataRepo\n    end\n    \n    subgraph Main [\"Main Project\"]\n        direction LR\n        MainRepo --&gt; MainBranch\n        MainRepo --&gt; GHPages\n        GHPages --&gt; Website\n    end\n\n    subgraph Apps [\"Shiny Applications\"]\n        direction LR\n        ShinyRepo1 --&gt; ShinyApp1\n        ShinyRepo2 --&gt; ShinyApp2\n    end\n\n    %% Connections between subgraphs\n    MainRepo -.-&gt; Package\n    DataRepo -.-&gt; MainRepo\n    Package -.-&gt; ShinyRepo1\n    Package -.-&gt; ShinyRepo2\n    Website -.-&gt; PackageWeb\n    Website -.-&gt; ShinyApp1\n    Website -.-&gt; ShinyApp2",
    "crumbs": [
      "Home",
      "Conclusions and Sharing",
      "10. Sharing"
    ]
  },
  {
    "objectID": "sharing.html#github-code-sharing",
    "href": "sharing.html#github-code-sharing",
    "title": "Sharing",
    "section": "GitHub Code Sharing",
    "text": "GitHub Code Sharing\nAll the code that I wrote, and in some cases co-wrote with Claude.AI and/or Perplexity.AI, is available in my GitHub repositories, in the following ways.\n\nconcertData R-package\nhttps://github.com/vanleeuwen-hans/concertData\nThis is my concertData R-package where I organized the functions I wrote to perform all the data processing, analytics and visualization as part of my Capstone Project for the Google Data analytics Certification.\n\n\nconcertData Documentation\nhttps://vanleeuwen-hans.github.io/concertData/index.html\nWith pkgdown I was able to easily create documentation web pages for my concertData R-package.\n# install and load library\ninstall.packages(\"pkgdown\")\nlibrary(pkgdown)\n\n# In the package directory, run:\nusethis::use_pkgdown()\n# This will create a _pkgdown.yml configuration file and add necessary entries to .gitignore\n\n# To build the site locally in R-Studio, use:\npkgdown::build_site()\n# This will create a docs/ directory with your website files\n\n# Automate deployment with GitHub Pages\nusethis::use_pkgdown_github_pages()\n# This sets up GitHub Actions to automatically build and deploy your site whenever you push changes to your repository\nThe resulting website includes:\n\nA homepage based on your README.md\nReference pages for all exported functions\n\nThe changes can then be committed and pushed to GitHub from R-Studio.\n\n\nCode Chunks in the Quarto Report\nI used Quarto to publish my Capstone Project report for the Google Data analytics Certification, containing my methods, analysis code chunks, results including plots, insights and lessons learned. More about the set-up in the next paragraph. Some example R Code chunks with my analysis code and outputs can be seen at my U2 Data Analytics Quarto web site.",
    "crumbs": [
      "Home",
      "Conclusions and Sharing",
      "10. Sharing"
    ]
  },
  {
    "objectID": "sharing.html#quarto-report-on-github-pages",
    "href": "sharing.html#quarto-report-on-github-pages",
    "title": "Sharing",
    "section": "Quarto Report on GitHub Pages",
    "text": "Quarto Report on GitHub Pages\n\nIntroduction\nTo write my report for the Google Data Analytics Certification Capstone Project I first experimented with basic R Markdown pages, but then switched to Quarto which was easy having a report with multiple pages, and it is convenient to share and publish it on GitHub Pages. Basically, the Quarto Report that you are reading now was created as I advanced in my project, and includes all the analysis steps. The report pages are automatically rendered at which point the analysis code is executed and the resulting output, tables or plots are included in the report page. The structure of the report is created in the _quarto.yml file in the R Studio project folder, and then the individual Quarto documents with the sections of the report are automatically linked into one web site.\n\n\nSetting up the Quarto website\nThe initial push of my rendered Quarto documents to my GitHub repository and GitHub Pages was a challenge as there were many files, including images, and the total size made the process fail. Here is how I set it up:\nIn my GitHub account I created a new repository: u2_data_analytics, with nothing in it. In the Settings &gt; Pages section I selected to deploy from the gh-pages branch (see below) and from the docs folder. That is the Folder where Quarto renders and creates the website files.\nLocally, in the folder of my R Studio project u2_data_analytics, I worked on the MacOS terminal:\n# initialise git repository locally\n% git init \nInitialized empty Git repository in u2_data_analytics/.git/\n\n# link it to the online GitHuB repository\n% git remote add origin https://github.com/vanleeuwen-hans/u2_data_analytics.git\n\n# pull from remote main branch\n% git pull origin main \nFrom https://github.com/vanleeuwen-hans/u2_data_analytics \n* branch main -&gt; FETCH_HEAD\n\n# create gh-pages branch that will be used for publishing Quarto Report pages only\n% git checkout -b gh-pages \nSwitched to a new branch 'gh-pages'\n\n# Push the new branch to remote\n\n% git push origin gh-pages \nTotal 0 (delta 0), reused 0 (delta 0), pack-reused 0 remote: \nremote: Create a pull request for 'gh-pages' on GitHub by visiting: remote: https://github.com/vanleeuwen-hans/u2_data_analytics/pull/new/gh-pages remote: \nTo https://github.com/vanleeuwen-hans/u2_data_analytics.git \\* \\[new branch\\] gh-pages -\\&gt; gh-pages\n\n# Set upstream to track remote branch\n# Pushes your local gh-pages branch to the remote repository (origin) \n# 2 Sets up tracking between your local and remote branch, which means: \n# ‚ó¶ Future git pull commands will know to pull from origin/gh-pages \n# ‚ó¶ Future git push commands will know to push to origin/gh-pages \n# ‚ó¶ You can see the branch's status compared to remote with git status \n# Without setting the upstream, you'd need to type git push origin gh-pages every time. \n# After setting it, you can simply type git push or git pull. \n% git push --set-upstream origin gh-pages \nbranch 'gh-pages' set up to track 'origin/gh-pages'. Everything up-to-date\n\n# check status\n% git status On branch gh-pages \nYour branch is up to date with 'origin/gh-pages'. \nUntracked files: (use \"git add &lt;file&gt;...\" to include in what will be committed) ‚Ä¶ \nnothing added to commit but untracked files present (use \"git add\" to track)\n\n# add content from docs folder, but not all at once\n# as that will be too big and result in failure\n% git add docs/index.html \n% git commit -m \"Adding Quarto pages in batches\" \n[gh-pages e8e6ad6] Adding Quarto pages in batches 1 file changed, \n8 insertions(+) create mode 100644 docs/index.html \n\n% git push \nEnumerating objects: 5, done. Counting objects: 100% (5/5), done. \nDelta compression using up to 4 threads \nCompressing objects: 100% (3/3), done. \nWriting objects: 100% (4/4), 490 bytes \\| 6.00 KiB/s, done. \nTotal 4 (delta 0), reused 0 (delta 0), pack-reused 0 To https://github.com/vanleeuwen-hans/u2_data_analytics.git \ne4ce103..e8e6ad6 gh-pages -&gt; gh-pages\n\n# continue adding, committing and pushing in small batches\n# until there are no untracked files left\n...\nAt some point I also discovered a way to increase the buffer size to allow bigger pushes to Github:\ngit config --global http.postBuffer 524288000\n\n\nMaintenance and Updates\nThe setup is to have two branches in the u2_data_analytics repository:\n\nmain: where project files are manged - not needed for the published web site\ngh-pages:documents needed for the published web site - the result of Quarto render\n\nInitially I had a process that involved many manual steps to push changes to my Quarto web site. That was until I asked Claude.AI (3.5 Sonnet) for help. The details how that was achieved are in the Generative AI Support &gt; Examples section of this report.\nThe process is simple, and as follows:\n\nMake changes to the Quarto documents in the main branch\nCommit and push to main\nGitHub Actions will automatically handle the rendering and deployment",
    "crumbs": [
      "Home",
      "Conclusions and Sharing",
      "10. Sharing"
    ]
  },
  {
    "objectID": "sharing.html#shiny-apps",
    "href": "sharing.html#shiny-apps",
    "title": "Sharing",
    "section": "Shiny Apps",
    "text": "Shiny Apps\nThe Shiny Apps with interactive visualizations of U2 data that I developed in my project are hosted at: https://www.shinyapps.io/. These tools cannot be simply embedded in a static website like my U2 Data Analytics Quarto web site. The code for these Shiny Apps are managed in R Studio on my Mac, with connections to GitHub and shinyapps.io to facilitate code version management and easy deployment. See more info at: Interactive Visualizations.",
    "crumbs": [
      "Home",
      "Conclusions and Sharing",
      "10. Sharing"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "conclusions.html",
    "href": "conclusions.html",
    "title": "Conclusions and Sharing",
    "section": "",
    "text": "Coming soon",
    "crumbs": [
      "Home",
      "Conclusions and Sharing",
      "9. Conclusions"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "U2 Data Analytics",
    "section": "",
    "text": "Well, first of all because I am a big U2 fan, a spark that was lit when I purchased the single ‚ÄòPride (In the Name of Love)‚Äô in an old-school record store back in 1984. My U2 concert mania started after my sister gave me the album ‚ÄòRattle and Hum‚Äô for my 16th birthday - we had moved on from black records to CDs by then. I missed out on tickets for the Lovetown Tour at the turn of the decade, but did score a ticket for the ZOO TV Tour show on June 15th 1992, in Rotterdam, the Netherlands. I could write a book about the next decades, the albums and all the concerts I attended, but let‚Äôs not get carried away for now. So that was the first reason.\nSecond, I am a data scientist. I am a plant molecular biology and genetics scientist by training, and at some point in my professional journey I transitioned into bioinformatics, scripting, coding, trying to make sense of the avalanche of data coming from new genetic and genomic technologies like the Next-Gen Sequencing revolution in the first decade of this century. Now I work in pharmaceutical data science, data strategy and governance. So yes, you can say that I love to dig into data, to uncover hard to find insights that can help us to bring new medicine or treatments to people with unmet medical needs.\nThe work documented on this site is my Capstone Project for the Google Data Analytics Certification program.\n\n\n\n\n\n\nThis was a very good and exciting experience and taught me a lot of valuable lessons in all the different phases of data analytics: Ask, Prepare, Process, Analyze, Share and Act. In addition, during the data visualization part I combined forces with AI assistants (e.g.¬†Claude , Gemini and Perplexity) to troubleshoot the code and to create even better visualizations, e.g.¬†the zoomable, interactive world maps of U2 concert locations over time and the U2 Setlist Alignment app.\nThe data used in this project was obtained from the excellent online U2 concert resource u2gigs.com. Permission to do so was requested and kindly granted by Matt @ u2gigs.com. Thank you so much!\nA big thank you to my wife who has been on this U2 adventure with me and also provided very valuable feedback and input as I analyzed the data.\nEnjoy and let me know if you have any suggestions or other feedback.\nWho knows, perhaps we‚Äôll run into each other one day, either at a data science conference or a U2 concert ‚úåÔ∏è\nBest,\nHans van Leeuwen - November 2024\n\n\n\nHans in the Achtung Baby - ZOO TV era in his childhood room"
  },
  {
    "objectID": "index.html#why-u2-data-analytics",
    "href": "index.html#why-u2-data-analytics",
    "title": "U2 Data Analytics",
    "section": "",
    "text": "Well, first of all because I am a big U2 fan, a spark that was lit when I purchased the single ‚ÄòPride (In the Name of Love)‚Äô in an old-school record store back in 1984. My U2 concert mania started after my sister gave me the album ‚ÄòRattle and Hum‚Äô for my 16th birthday - we had moved on from black records to CDs by then. I missed out on tickets for the Lovetown Tour at the turn of the decade, but did score a ticket for the ZOO TV Tour show on June 15th 1992, in Rotterdam, the Netherlands. I could write a book about the next decades, the albums and all the concerts I attended, but let‚Äôs not get carried away for now. So that was the first reason.\nSecond, I am a data scientist. I am a plant molecular biology and genetics scientist by training, and at some point in my professional journey I transitioned into bioinformatics, scripting, coding, trying to make sense of the avalanche of data coming from new genetic and genomic technologies like the Next-Gen Sequencing revolution in the first decade of this century. Now I work in pharmaceutical data science, data strategy and governance. So yes, you can say that I love to dig into data, to uncover hard to find insights that can help us to bring new medicine or treatments to people with unmet medical needs.\nThe work documented on this site is my Capstone Project for the Google Data Analytics Certification program.\n\n\n\n\n\n\nThis was a very good and exciting experience and taught me a lot of valuable lessons in all the different phases of data analytics: Ask, Prepare, Process, Analyze, Share and Act. In addition, during the data visualization part I combined forces with AI assistants (e.g.¬†Claude , Gemini and Perplexity) to troubleshoot the code and to create even better visualizations, e.g.¬†the zoomable, interactive world maps of U2 concert locations over time and the U2 Setlist Alignment app.\nThe data used in this project was obtained from the excellent online U2 concert resource u2gigs.com. Permission to do so was requested and kindly granted by Matt @ u2gigs.com. Thank you so much!\nA big thank you to my wife who has been on this U2 adventure with me and also provided very valuable feedback and input as I analyzed the data.\nEnjoy and let me know if you have any suggestions or other feedback.\nWho knows, perhaps we‚Äôll run into each other one day, either at a data science conference or a U2 concert ‚úåÔ∏è\nBest,\nHans van Leeuwen - November 2024\n\n\n\nHans in the Achtung Baby - ZOO TV era in his childhood room"
  },
  {
    "objectID": "generative-ai-support.html#examples",
    "href": "generative-ai-support.html#examples",
    "title": "Generative AI Support",
    "section": "Examples",
    "text": "Examples\n\nBrainstorming ideas for data analytics and visuals\n\n\nTroubleshooting coding errors\n\n\nAdvise for tools and hosting platforms\n\n\nCreating the structure for an R Package\n\n\nAutomating the deployment of changes in the Quarto web site\nAs explained in the Sharing &gt; Maintenance and Updates section, I initially had a cumbersome process that involved many manual steps to push changes to my Quarto web site. That was until I asked Claude.AI (3.5 Sonnet) for help. Here was my prompt:\n\n\nI have my R Studio project u2_data_analytics. I have a git repository locally and on GitHub. All the Quarto rendered files are in the docs folder and in the gh-pages branch, and published on GitHub pages. The rest is in the main branch.\n\nThe process to update is currently cumbersome. I update qmd documents in main, render these, copy the new files from docs temporarily and manually somewhere outside of my project folder, then do a git stash, after which I switch to the gh-pages branch, then manually copy paste the new files into the docs folder of the gh-pages branch, followed by git add, commit and push.\n\nIs there a more automated way to deploy my qmd file changes to the Quarto site that is on GitHub pages?\n\nThis was Claude‚Äôs response:\n\nI understand you want to streamline the process of updating your Quarto site deployed on GitHub Pages. Yes, there‚Äôs a much simpler automated approach using GitHub Actions. Let me create a workflow file that will handle this automatically.\nGitHub Actions workflow for Quarto publishing (code was provided)\nTo implement this automated workflow:\nCreate a .github/workflows directory in your repository‚Äôs main branch:\nmkdir -p .github/workflows\nSave the workflow file I provided as .github/workflows/quarto-publish.yml\nCommit and push these changes to your main branch:\ngit add .github/workflows/quarto-publish.yml\ngit commit -m \"Add Quarto publishing workflow\"\ngit push origin main\nThis workflow will:\n\nTrigger automatically when you push changes to .qmd, .Rmd, or .md files in the main branch\nSet up R and Quarto in the GitHub Actions environment\nInstall your R dependencies using renv\nRender your Quarto project\nAutomatically deploy the rendered files to the gh-pages branch\n\nNow your process becomes much simpler:\n\nMake changes to your Quarto documents in the main branch\nCommit and push to main\nGitHub Actions will automatically handle the rendering and deployment\n\nThe changes should appear on your GitHub Pages site within a few minutes after pushing to main.\nWould you like me to explain any part of this workflow in more detail?\n\nI implemented this but there was a failure on the first attempt. That was due to a missing renv.lock file in my repository. As Claude.AI had timed out (I have a free account) I went to Perplexity.AI who helped to resolve this issue:\n\n\nThe error ‚ÄúThis project does not contain a lockfile‚Äù suggests that you‚Äôre using a package management system (likely renv for R or pip for Python) but haven‚Äôt created a lockfile yet. Here‚Äôs how to resolve this:\n\nLocally, in your R project, run:\n\nrenv::snapshot()\nThis will create a renv.lock file in your project directory.\n\nCommit and push the renv.lock file to your repository.\n\n\nWhen I created the renv.lock file I got a warning about my local loading of my concertData R package, so I changed the loading of that package in my Quarto code chunks:\nFrom: devtools::load_all(\"../packages/concertData\")\nTo: devtools::install_github(\"vanleeuwen-hans/concertData\")\nAnd that was basically it, now the deployment is fully automated whenever I change something in my report qmd files and push it to GitHub.\n\n\nConnecting with a private repository to protect sensitive data",
    "crumbs": [
      "Home",
      "Conclusions and Sharing",
      "11. Generative AI Support"
    ]
  }
]